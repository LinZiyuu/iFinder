from __future__ import annotations

import json
import re
import shutil
import subprocess
import time
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Callable

from ifinder_sdk.config import (
    AttackVectorDocument,
    CrashEvidence,
    CrashLocation,
    ExploitationResult,
    ExploitationVerdict,
    ProtocolType,
    iTrueCandidate,
)


MessageSchemaMap = dict[str, dict[str, Any]]
ExecuteOnceFn = Callable[[Path, AttackVectorDocument, int], dict[str, Any]]

_PFCP_MESSAGE_TYPE_HINTS = {
    "PFCP_Heartbeat_Request": 1,
    "PFCP_Heartbeat_Response": 2,
    "PFCP_PFD_Management_Request": 3,
    "PFCP_PFD_Management_Response": 4,
    "PFCP_Session_Establishment_Request": 50,
    "PFCP_Session_Establishment_Response": 51,
    "PFCP_Session_Modification_Request": 52,
    "PFCP_Session_Modification_Response": 53,
    "PFCP_Session_Deletion_Request": 54,
    "PFCP_Session_Deletion_Response": 55,
    "PFCP_Session_Report_Request": 56,
    "PFCP_Session_Report_Response": 57,
    "PFCP_Session_Set_Deletion_Request": 58,
    "PFCP_Session_Set_Deletion_Response": 59,
    "PFCP_Association_Setup_Request": 5,
    "PFCP_Association_Setup_Response": 6,
    "PFCP_Association_Update_Request": 7,
    "PFCP_Association_Update_Response": 8,
    "PFCP_Association_Release_Request": 9,
    "PFCP_Association_Release_Response": 10,
    "PFCP_Version_Not_Supported_Response": 11,
    "PFCP_Node_Report_Request": 12,
    "PFCP_Node_Report_Response": 13,
}

_CRASH_KEYWORDS = [
    "asan",
    "heap-buffer-overflow",
    "segmentation fault",
    "segfault",
    "assertion",
    "panic",
    "fatal",
    "nil pointer",
    "core dumped",
    "out of bounds",
]

_DIAGNOSIS_RULES: list[tuple[str, str, str]] = [
    ("unknown teid", "TEID mismatch", "extract_teid_from_prior_message"),
    ("invalid sequence", "Sequence mismatch", "match_sequence_with_request"),
    ("missing mandatory ie", "Mandatory IE missing", "add_missing_mandatory_ie"),
    ("association not found", "PFCP association missing", "establish_association_first"),
    ("session not found", "Session context missing", "establish_session_first"),
]


def load_message_schemas(message_schemas: dict[str, Any] | str | Path | None) -> MessageSchemaMap:
    if message_schemas is None:
        return {}
    if isinstance(message_schemas, dict):
        return _normalize_schema_map(message_schemas)

    path = Path(message_schemas)
    if not path.exists():
        raise FileNotFoundError(f"Message schema file not found: {path}")
    with open(path, encoding="utf-8") as fp:
        data = json.load(fp)
    return _normalize_schema_map(data)


def derive_attack_vector_and_messages(
    candidate: iTrueCandidate | dict[str, Any],
    *,
    message_schemas: dict[str, Any] | str | Path | None = None,
    prerequisite_messages: list[str] | None = None,
    protocol: ProtocolType = ProtocolType.PFCP,
) -> AttackVectorDocument:
    cand = _normalize_candidate(candidate)
    schema_map = load_message_schemas(message_schemas)

    trigger_message = _normalize_message_name(cand.trigger_message, protocol)
    prior_messages = list(dict.fromkeys(prerequisite_messages or []))
    target_entity = _infer_target_entity(cand)
    target_interface = "N4" if protocol == ProtocolType.PFCP else "S11/S5c"
    attacker_role = _infer_attacker_role(target_entity)

    expected_buffer_size = _infer_expected_buffer_size(cand)
    malicious_value = _infer_malicious_value(cand, expected_buffer_size)
    expected_outcome = _infer_expected_outcome(cand)

    steps: list[dict[str, Any]] = []
    step_no = 1
    for msg in prior_messages:
        action = "respond" if msg.endswith("Response") else "send"
        steps.append(
            {
                "step": step_no,
                "message": msg,
                "manipulation": {
                    "ie": cand.trigger_ie or "UnknownIE",
                    "field": cand.ie_field or "unknown_field",
                    "malicious_value": "<benign_placeholder>",
                },
                "triggers_vulnerability": False,
                "action": action,
            }
        )
        step_no += 1

    action = "respond" if trigger_message.endswith("Response") else "send"
    steps.append(
        {
            "step": step_no,
            "message": trigger_message,
            "manipulation": {
                "ie": cand.trigger_ie or "UnknownIE",
                "field": cand.ie_field or "unknown_field",
                "malicious_value": malicious_value,
                "expected_buffer_size": expected_buffer_size,
            },
            "triggers_vulnerability": True,
            "action": action,
        }
    )

    protocol_messages: dict[str, dict[str, Any]] = {}
    for msg in prior_messages + [trigger_message]:
        mandatory_ies = _extract_mandatory_ies(schema_map, msg)
        is_trigger = msg == trigger_message
        protocol_messages[msg] = _build_protocol_message_spec(
            message_name=msg,
            mandatory_ies=mandatory_ies,
            trigger_ie=cand.trigger_ie,
            ie_field=cand.ie_field,
            malicious_value=malicious_value if is_trigger else "<benign_placeholder>",
            include_attack_payload=is_trigger,
        )

    attack_doc = AttackVectorDocument(
        candidate_id=cand.id,
        attack_vector={
            "target_entity": target_entity,
            "target_interface": target_interface,
            "attacker_role": attacker_role,
            "attack_sequence": steps,
            "expected_outcome": expected_outcome,
        },
        protocol_messages=protocol_messages,
    )
    return attack_doc


def generate_poc_from_attack_vector(
    attack_doc: AttackVectorDocument | dict[str, Any],
    output_root: str | Path,
    *,
    candidate: iTrueCandidate | dict[str, Any] | None = None,
    pattern_id: str | None = None,
    target_version: str | None = None,
    target_software: str | None = None,
) -> Path:
    doc = _normalize_attack_doc(attack_doc)
    cand = _normalize_candidate(candidate) if candidate is not None else None
    output_root_path = Path(output_root)
    poc_dir = output_root_path / doc.candidate_id
    poc_dir.mkdir(parents=True, exist_ok=True)

    attack_path = poc_dir / "attack_vector.json"
    attack_payload = json.dumps(doc.model_dump(), indent=2) + "\n"
    attack_path.write_text(attack_payload, encoding="utf-8")

    raw_hex = _extract_raw_hex_from_attack_doc(doc)

    attack_procedure = _build_attack_procedure_doc(
        doc=doc,
        candidate=cand,
        pattern_id=pattern_id,
        target_version=target_version,
        target_software=target_software,
        raw_hex=raw_hex,
    )
    if attack_procedure:
        (poc_dir / "attack_procedure.json").write_text(
            json.dumps(attack_procedure, indent=2) + "\n", encoding="utf-8"
        )

    go_mod = f"""module poc/{doc.candidate_id}

go 1.21

require github.com/wmnsk/go-pfcp v0.0.24
"""
    (poc_dir / "go.mod").write_text(go_mod, encoding="utf-8")

    runtime_path = (
        Path(__file__).resolve().parent.parent / "assets" / "poc" / "pfcp_runtime.go"
    )
    if runtime_path.exists():
        main_go = runtime_path.read_text(encoding="utf-8")
    else:
        trigger_message = _get_trigger_message(doc)
        main_go = f'''package main

import (
    "encoding/json"
    "fmt"
    "os"
)

func main() {{
    raw, err := os.ReadFile("attack_vector.json")
    if err != nil {{
        fmt.Println("failed to read attack_vector.json:", err)
        os.Exit(1)
    }}

    var payload map[string]any
    if err := json.Unmarshal(raw, &payload); err != nil {{
        fmt.Println("failed to parse attack_vector.json:", err)
        os.Exit(1)
    }}

    fmt.Println("Loaded attack vector for candidate: {doc.candidate_id}")
    fmt.Println("Trigger message: {trigger_message}")
    fmt.Println("PoC scaffold generated. Implement protocol send path here.")
}}
'''
    (poc_dir / "main.go").write_text(main_go, encoding="utf-8")

    readme = f"""# PoC for {doc.candidate_id}

This PoC was generated from `attack_vector.json`.

## Files
- `main.go`: PoC scaffold entrypoint
- `go.mod`: module definition
- `attack_vector.json`: attack vector and protocol messages

## Build
```bash
go build -o poc_binary .
```

## Run
Client mode (send requests):
```bash
./poc_binary -target <PFCP_IP> -local <LOCAL_IP> -seid <SEID> -timeout <SECONDS>
```

Server mode (respond with responses):
```bash
./poc_binary -listen <LISTEN_IP> -local <LOCAL_IP> -seid <SEID> -timeout <SECONDS>
```
"""
    (poc_dir / "README.md").write_text(readme, encoding="utf-8")

    return poc_dir


def run_pre_execution_checks(
    poc_dir: str | Path,
    attack_doc: AttackVectorDocument | dict[str, Any],
) -> dict[str, Any]:
    doc = _normalize_attack_doc(attack_doc)
    base = Path(poc_dir)

    required_files = ["main.go", "go.mod", "attack_vector.json", "README.md"]
    missing = [name for name in required_files if not (base / name).exists()]
    files_ok = not missing

    consistency_ok, consistency_issues = _check_attack_vector_consistency(base, doc)
    equivalence_ok, equivalence_issues = _check_poc_equivalence(base, doc)
    compile_ok, compile_stdout, compile_stderr = _run_go_build(base)

    issues = []
    if missing:
        issues.append(f"Missing required files: {', '.join(missing)}")
    issues.extend(consistency_issues)
    issues.extend(equivalence_issues)
    if not compile_ok:
        issues.append("Go compilation failed or Go toolchain unavailable.")

    return {
        "files_ok": files_ok,
        "consistency_ok": consistency_ok,
        "equivalence_ok": equivalence_ok,
        "compile_ok": compile_ok,
        "compile_stdout": compile_stdout,
        "compile_stderr": compile_stderr,
        "overall_ok": files_ok and consistency_ok and equivalence_ok and compile_ok,
        "issues": issues,
    }


def feedback_aware_refinement_loop(
    attack_doc: AttackVectorDocument | dict[str, Any],
    *,
    poc_dir: str | Path,
    execute_once: ExecuteOnceFn,
    max_iterations: int = 5,
    expected_file: str | None = None,
    expected_function: str | None = None,
) -> ExploitationResult:
    current_doc = _normalize_attack_doc(attack_doc)
    base = Path(poc_dir)
    refinements: list[str] = []

    for attempt in range(1, max_iterations + 1):
        exec_result = execute_once(base, current_doc, attempt)
        logs = str(exec_result.get("logs", ""))
        analysis = analyze_runtime_logs(logs)

        if analysis["crash_detected"]:
            location = analysis.get("crash_location") or {}
            matched = _is_expected_crash(
                location=location,
                expected_file=expected_file,
                expected_function=expected_function,
            )
            verdict = (
                ExploitationVerdict.CONFIRMED
                if matched
                else ExploitationVerdict.TRIGGERED_DIFFERENT
            )
            crash_location = CrashLocation(
                file=str(location.get("file", "unknown")),
                line=int(location.get("line", 0)),
                function=str(location.get("function", "unknown")),
            )
            crash_evidence = CrashEvidence(
                type=str(analysis.get("crash_type", "unknown")),
                location=crash_location,
                log_snippet=analysis.get("log_snippet", []),
            )
            return ExploitationResult(
                candidate_id=current_doc.candidate_id,
                validation_result=verdict,
                timestamp=datetime.now(timezone.utc),
                attempts=attempt,
                crash_evidence=crash_evidence,
                poc_path=str(base / "main.go"),
                refinements_attempted=refinements or None,
            )

        if attempt == max_iterations:
            diagnosis = analysis.get("diagnosis") or str(exec_result.get("error") or "No crash observed.")
            return ExploitationResult(
                candidate_id=current_doc.candidate_id,
                validation_result=ExploitationVerdict.UNCONFIRMED,
                timestamp=datetime.now(timezone.utc),
                attempts=attempt,
                poc_path=str(base / "main.go"),
                failure_analysis=diagnosis,
                refinements_attempted=refinements or None,
            )

        updated_doc, action = apply_feedback_refinement(current_doc, analysis)
        refinements.append(action)
        current_doc = updated_doc
        (base / "attack_vector.json").write_text(
            json.dumps(current_doc.model_dump(), indent=2) + "\n",
            encoding="utf-8",
        )

    return ExploitationResult(
        candidate_id=current_doc.candidate_id,
        validation_result=ExploitationVerdict.UNCONFIRMED,
        timestamp=datetime.now(timezone.utc),
        attempts=max_iterations,
        poc_path=str(base / "main.go"),
        failure_analysis="Execution loop ended without result.",
        refinements_attempted=refinements or None,
    )


def analyze_runtime_logs(logs: str) -> dict[str, Any]:
    lowered = logs.lower()
    crash_detected = any(keyword in lowered for keyword in _CRASH_KEYWORDS)
    crash_type = _infer_crash_type(lowered) if crash_detected else None
    crash_location = _extract_crash_location(logs) if crash_detected else None
    snippet = _extract_log_snippet(logs)

    diagnosis = "No decisive runtime signal."
    refinement_action = "none"
    for pattern, diag, action in _DIAGNOSIS_RULES:
        if pattern in lowered:
            diagnosis = diag
            refinement_action = action
            break

    if crash_detected:
        diagnosis = "Crash observed during execution."
        refinement_action = "none"

    missing_ie = _extract_missing_ie(logs)
    return {
        "crash_detected": crash_detected,
        "crash_type": crash_type,
        "crash_location": crash_location,
        "diagnosis": diagnosis,
        "refinement_action": refinement_action,
        "missing_ie": missing_ie,
        "log_snippet": snippet,
    }


def apply_feedback_refinement(
    attack_doc: AttackVectorDocument | dict[str, Any],
    analysis: dict[str, Any],
) -> tuple[AttackVectorDocument, str]:
    doc = _normalize_attack_doc(attack_doc)
    action = str(analysis.get("refinement_action", "none"))

    data = doc.model_dump()
    trigger_msg = _get_trigger_message(doc)
    trigger_spec = data["protocol_messages"].setdefault(trigger_msg, {"header": {}, "ies": {}})
    trigger_header = trigger_spec.setdefault("header", {})
    trigger_ies = trigger_spec.setdefault("ies", {})

    if action == "extract_teid_from_prior_message":
        trigger_header["teid"] = "<extract_from_prior_message>"
        return AttackVectorDocument.model_validate(data), "Set trigger TEID to dynamic extraction placeholder."

    if action == "match_sequence_with_request":
        trigger_header["sequence_number"] = "<match_request_sequence>"
        return AttackVectorDocument.model_validate(data), "Set sequence number to match request transaction."

    if action == "add_missing_mandatory_ie":
        missing_ie = analysis.get("missing_ie") or "UnknownMandatoryIE"
        trigger_ies.setdefault(str(missing_ie), {"value": "<placeholder>"})
        return AttackVectorDocument.model_validate(data), f"Added missing mandatory IE placeholder: {missing_ie}."

    if action == "establish_association_first":
        _prepend_messages_if_missing(
            data,
            [
                "PFCP_Association_Setup_Request",
                "PFCP_Association_Setup_Response",
            ],
        )
        return AttackVectorDocument.model_validate(data), "Prepended association setup messages."

    if action == "establish_session_first":
        _prepend_messages_if_missing(
            data,
            [
                "PFCP_Session_Establishment_Request",
                "PFCP_Session_Establishment_Response",
            ],
        )
        return AttackVectorDocument.model_validate(data), "Prepended session establishment messages."

    return doc, "No refinement rule matched."


def execute_in_docker_testbed_once(
    poc_dir: Path,
    attack_doc: AttackVectorDocument,
    attempt: int,
    *,
    docker_container: str,
    target_port: int = 8805,
    wait_seconds: float = 2.0,
) -> dict[str, Any]:
    if shutil.which("docker") is None:
        return {"status": "error", "error": "docker command not found", "logs": ""}

    binary = poc_dir / "poc_binary"
    if not binary.exists():
        return {"status": "error", "error": f"missing binary: {binary}", "logs": ""}

    restart = subprocess.run(
        ["docker", "restart", docker_container],
        capture_output=True,
        text=True,
        check=False,
    )
    if restart.returncode != 0:
        return {
            "status": "error",
            "error": f"failed to restart container {docker_container}",
            "logs": restart.stdout + restart.stderr,
        }

    inspect = subprocess.run(
        [
            "docker",
            "inspect",
            docker_container,
            "--format",
            "{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}",
        ],
        capture_output=True,
        text=True,
        check=False,
    )
    target_ip = inspect.stdout.strip()
    if inspect.returncode != 0 or not target_ip:
        return {
            "status": "error",
            "error": f"failed to inspect container ip for {docker_container}",
            "logs": inspect.stdout + inspect.stderr,
        }

    run = subprocess.run(
        [str(binary), "-target", f"{target_ip}:{target_port}"],
        cwd=str(poc_dir),
        capture_output=True,
        text=True,
        check=False,
    )
    time.sleep(wait_seconds)

    logs = subprocess.run(
        ["docker", "logs", docker_container, "--tail", "200"],
        capture_output=True,
        text=True,
        check=False,
    )
    combined_logs = "\n".join(
        [
            f"attempt={attempt}",
            run.stdout,
            run.stderr,
            logs.stdout,
            logs.stderr,
        ]
    )
    return {"status": "ok", "logs": combined_logs}


def execute_local_poc_once(
    poc_dir: Path,
    attack_doc: AttackVectorDocument,
    attempt: int,
    *,
    target_ip: str | None,
    listen_ip: str | None = None,
    local_ip: str | None = None,
    seid: int | None = None,
    timeout: int | None = None,
) -> dict[str, Any]:
    binary = poc_dir / "poc_binary"
    if not binary.exists():
        return {"status": "error", "error": f"missing binary: {binary}", "logs": ""}

    args = [str(binary)]
    if listen_ip:
        args += ["-listen", listen_ip]
    elif target_ip:
        args += ["-target", target_ip]
    if local_ip:
        args += ["-local", local_ip]
    if seid is not None:
        args += ["-seid", str(seid)]
    if timeout is not None:
        args += ["-timeout", str(timeout)]

    run = subprocess.run(
        args,
        cwd=str(poc_dir),
        capture_output=True,
        text=True,
        check=False,
    )
    combined_logs = "\n".join(
        [
            f"attempt={attempt}",
            run.stdout,
            run.stderr,
        ]
    )
    return {"status": "ok", "logs": combined_logs}


def exploit_candidate(
    candidate: iTrueCandidate | dict[str, Any],
    *,
    output_root: str | Path,
    message_schemas: dict[str, Any] | str | Path | None = None,
    prerequisite_messages: list[str] | None = None,
    protocol: ProtocolType = ProtocolType.PFCP,
    docker_container: str | None = None,
    target_ip: str | None = None,
    listen_ip: str | None = None,
    local_ip: str | None = None,
    seid: int | None = None,
    timeout: int | None = None,
    max_iterations: int = 5,
    expected_file: str | None = None,
    expected_function: str | None = None,
    pattern_id: str | None = None,
    target_version: str | None = None,
    target_software: str | None = None,
) -> dict[str, Any]:
    attack_doc = derive_attack_vector_and_messages(
        candidate,
        message_schemas=message_schemas,
        prerequisite_messages=prerequisite_messages,
        protocol=protocol,
    )
    poc_dir = generate_poc_from_attack_vector(
        attack_doc,
        output_root,
        candidate=candidate,
        pattern_id=pattern_id,
        target_version=target_version,
        target_software=target_software,
    )
    precheck = run_pre_execution_checks(poc_dir, attack_doc)

    if not precheck["overall_ok"]:
        result = ExploitationResult(
            candidate_id=attack_doc.candidate_id,
            validation_result=ExploitationVerdict.UNCONFIRMED,
            timestamp=datetime.now(timezone.utc),
            attempts=0,
            poc_path=str(Path(poc_dir) / "main.go"),
            failure_analysis="; ".join(precheck["issues"]) or "Pre-execution checks failed.",
            refinements_attempted=None,
        )
        return {
            "attack_vector": attack_doc,
            "poc_dir": str(poc_dir),
            "precheck": precheck,
            "result": result,
        }

    if docker_container:
        def _executor(poc: Path, doc: AttackVectorDocument, attempt: int) -> dict[str, Any]:
            return execute_in_docker_testbed_once(
                poc,
                doc,
                attempt,
                docker_container=docker_container,
            )

        result = feedback_aware_refinement_loop(
            attack_doc,
            poc_dir=poc_dir,
            execute_once=_executor,
            max_iterations=max_iterations,
            expected_file=expected_file,
            expected_function=expected_function,
        )
    elif target_ip:
        def _executor(poc: Path, doc: AttackVectorDocument, attempt: int) -> dict[str, Any]:
            return execute_local_poc_once(
                poc,
                doc,
                attempt,
                target_ip=target_ip,
                listen_ip=listen_ip,
                local_ip=local_ip,
                seid=seid,
                timeout=timeout,
            )

        result = feedback_aware_refinement_loop(
            attack_doc,
            poc_dir=poc_dir,
            execute_once=_executor,
            max_iterations=max_iterations,
            expected_file=expected_file,
            expected_function=expected_function,
        )
    else:
        result = ExploitationResult(
            candidate_id=attack_doc.candidate_id,
            validation_result=ExploitationVerdict.UNCONFIRMED,
            timestamp=datetime.now(timezone.utc),
            attempts=0,
            poc_path=str(Path(poc_dir) / "main.go"),
            failure_analysis=(
                "No runtime executor configured. Provide docker_container or target_ip to execute."
            ),
            refinements_attempted=None,
        )

    return {
        "attack_vector": attack_doc,
        "poc_dir": str(poc_dir),
        "precheck": precheck,
        "result": result,
    }


def _normalize_candidate(candidate: iTrueCandidate | dict[str, Any]) -> iTrueCandidate:
    if isinstance(candidate, iTrueCandidate):
        return candidate

    data = dict(candidate)
    vuln_site = data.get("vulnerable_site") or {
        "file": data.get("code_file", "unknown_file"),
        "line": int(data.get("code_line", 0)),
        "function": data.get("vulnerable_function", "unknown_function"),
        "dangerous_operation": data.get("dangerous_operation", "unknown_operation"),
    }

    mapped = {
        "id": data.get("id") or data.get("candidate_id") or "UNKNOWN-CANDIDATE",
        "vulnerable_site": vuln_site,
        "trigger_message": data.get("trigger_message") or data.get("message_type") or "UnknownMessage",
        "trigger_ie": data.get("trigger_ie") or data.get("ie_name") or "UnknownIE",
        "ie_field": data.get("ie_field") or data.get("trigger_ie") or "unknown_field",
        "data_flow": data.get("data_flow") or "unknown_data_flow",
        "call_chain": data.get("call_chain") or [],
    }
    return iTrueCandidate.model_validate(mapped)


def _normalize_attack_doc(attack_doc: AttackVectorDocument | dict[str, Any]) -> AttackVectorDocument:
    if isinstance(attack_doc, AttackVectorDocument):
        return attack_doc
    return AttackVectorDocument.model_validate(attack_doc)


def _normalize_schema_map(data: dict[str, Any]) -> MessageSchemaMap:
    if "messages" in data and isinstance(data["messages"], dict):
        raw = data["messages"]
    else:
        raw = data

    normalized: MessageSchemaMap = {}
    for name, spec in raw.items():
        if isinstance(name, str) and isinstance(spec, dict):
            normalized[name] = spec
    return normalized


def _normalize_message_name(message: str, protocol: ProtocolType) -> str:
    msg = message.strip()
    if protocol == ProtocolType.PFCP and not msg.startswith("PFCP_"):
        chunks = re.findall(r"[A-Z][a-z0-9]*|[A-Z]+(?![a-z])", msg)
        if chunks:
            msg = "PFCP_" + "_".join(chunks)
    return msg


def _infer_target_entity(candidate: iTrueCandidate) -> str:
    text = " ".join(
        [
            candidate.vulnerable_site.file,
            candidate.vulnerable_site.function,
            candidate.trigger_message,
        ]
    ).lower()
    if "smf" in text:
        return "SMF"
    if "upf" in text:
        return "UPF"
    if "sgwc" in text:
        return "SGW-C"
    if "pgwc" in text:
        return "PGW-C"
    return "UnknownEntity"


def _infer_attacker_role(target_entity: str) -> str:
    if target_entity in {"SMF", "SGW-C"}:
        return "Malicious UPF/PGW"
    if target_entity in {"UPF", "PGW-C"}:
        return "Malicious SMF/SGW"
    return "Malicious Peer"


def _infer_expected_buffer_size(candidate: iTrueCandidate) -> int | None:
    text = " ".join([candidate.vulnerable_site.dangerous_operation, candidate.data_flow])
    matches = re.findall(r"\b(\d{1,6})\b", text)
    if not matches:
        return None
    values = [int(x) for x in matches]
    positives = [x for x in values if x > 0]
    return min(positives) if positives else None


def _infer_malicious_value(candidate: iTrueCandidate, expected_buffer_size: int | None) -> Any:
    field = candidate.ie_field.lower()
    if any(token in field for token in ("len", "length", "size", "count")):
        if expected_buffer_size:
            return max(200, expected_buffer_size * 4)
        return 200
    if any(token in field for token in ("type", "state", "id")):
        return 9999
    return "<malicious_payload>"


def _infer_expected_outcome(candidate: iTrueCandidate) -> dict[str, Any]:
    op = candidate.vulnerable_site.dangerous_operation.lower()
    if "memcpy" in op or "memmove" in op or "strcpy" in op:
        crash_type = "heap_buffer_overflow"
    elif "assert" in op:
        crash_type = "assertion_failure"
    elif "panic" in op:
        crash_type = "panic"
    else:
        crash_type = "runtime_crash"

    return {
        "type": crash_type,
        "location": f"{candidate.vulnerable_site.file}:{candidate.vulnerable_site.line}",
        "impact": "Process crash (DoS)",
    }


def _extract_mandatory_ies(schema_map: MessageSchemaMap, message_name: str) -> list[str]:
    spec = schema_map.get(message_name, {})
    mandatory = spec.get("mandatory_ies")
    if isinstance(mandatory, list):
        return [str(x) for x in mandatory]

    ies = spec.get("ies")
    if isinstance(ies, dict):
        return [str(k) for k in ies.keys()]
    return []


def _build_protocol_message_spec(
    *,
    message_name: str,
    mandatory_ies: list[str],
    trigger_ie: str,
    ie_field: str,
    malicious_value: Any,
    include_attack_payload: bool,
) -> dict[str, Any]:
    header = {
        "message_type": _PFCP_MESSAGE_TYPE_HINTS.get(message_name, "<unknown_message_type>"),
        "teid": "<extract_from_prior_message>",
        "sequence_number": "<extract_from_prior_message>",
    }
    ies: dict[str, Any] = {name: {"value": "<mandatory_placeholder>"} for name in mandatory_ies}
    if include_attack_payload:
        ies[trigger_ie or "UnknownIE"] = {
            "field": ie_field or "unknown_field",
            "malicious_value": malicious_value,
        }
    return {"header": header, "ies": ies}


def _extract_raw_hex_from_attack_doc(doc: AttackVectorDocument) -> str:
    for step in doc.attack_vector.attack_sequence:
        if step.triggers_vulnerability:
            raw_hex = getattr(step.manipulation, "raw_hex", None)
            if raw_hex:
                return str(raw_hex)
    trigger = _get_trigger_message(doc)
    spec = doc.protocol_messages.get(trigger)
    if spec and getattr(spec, "raw_hex", None):
        return str(spec.raw_hex or "")
    return ""


def _build_attack_procedure_doc(
    *,
    doc: AttackVectorDocument,
    candidate: iTrueCandidate | None,
    pattern_id: str | None,
    target_version: str | None,
    target_software: str | None,
    raw_hex: str,
) -> dict[str, Any] | None:
    if not doc.attack_vector.attack_sequence:
        return None

    steps: list[dict[str, Any]] = []
    for step in doc.attack_vector.attack_sequence:
        steps.append(
            {
                "step": step.step,
                "message": step.message,
                "action": getattr(step, "action", "send"),
                "triggers_vulnerability": step.triggers_vulnerability,
                "manipulation": {
                    "ie": step.manipulation.ie,
                    "field": step.manipulation.field,
                    "malicious_value": step.manipulation.malicious_value,
                    "raw_hex": step.manipulation.raw_hex,
                    "raw_hex_kind": step.manipulation.raw_hex_kind,
                },
            }
        )

    expected_crash = None
    if candidate:
        expected_crash = {
            "type": doc.attack_vector.expected_outcome.type,
            "location": {
                "file": candidate.vulnerable_site.file,
                "line": candidate.vulnerable_site.line,
                "function": candidate.vulnerable_site.function,
            },
            "impact": doc.attack_vector.expected_outcome.impact,
        }

    payload: dict[str, Any] = {
        "vuln_id": doc.candidate_id,
        "pattern_id": pattern_id or "UNKNOWN",
        "target_software": target_software or "UnknownTarget",
        "target_version": target_version or "unknown",
        "attack_procedure": {
            "target_entity": doc.attack_vector.target_entity,
            "target_interface": doc.attack_vector.target_interface,
            "attacker_role": doc.attack_vector.attacker_role,
            "steps": steps,
            "expected_outcome": doc.attack_vector.expected_outcome.model_dump(),
        },
    }

    if expected_crash:
        payload["attack_procedure"]["expected_crash"] = expected_crash
    if raw_hex:
        payload["attack_procedure"]["raw_bytes"] = {"payload_hex": raw_hex}
    return payload


    ies: dict[str, Any] = {name: {"value": "<mandatory_placeholder>"} for name in mandatory_ies}
    if include_attack_payload:
        ies[trigger_ie or "UnknownIE"] = {
            "field": ie_field or "unknown_field",
            "malicious_value": malicious_value,
        }
    return {"header": header, "ies": ies}


def _get_trigger_message(attack_doc: AttackVectorDocument) -> str:
    for step in attack_doc.attack_vector.attack_sequence:
        if step.triggers_vulnerability:
            return step.message
    if attack_doc.attack_vector.attack_sequence:
        return attack_doc.attack_vector.attack_sequence[-1].message
    return "UnknownMessage"


def _check_attack_vector_consistency(
    poc_dir: Path,
    attack_doc: AttackVectorDocument,
) -> tuple[bool, list[str]]:
    issues: list[str] = []
    path = poc_dir / "attack_vector.json"
    if not path.exists():
        return False, ["attack_vector.json not found"]

    try:
        with open(path, encoding="utf-8") as fp:
            on_disk = AttackVectorDocument.model_validate(json.load(fp))
    except Exception as exc:  # noqa: BLE001
        return False, [f"attack_vector.json invalid: {exc}"]

    if on_disk.candidate_id != attack_doc.candidate_id:
        issues.append("Candidate ID mismatch between in-memory and on-disk attack vector.")
    if _get_trigger_message(on_disk) != _get_trigger_message(attack_doc):
        issues.append("Trigger message mismatch between in-memory and on-disk attack vector.")

    return len(issues) == 0, issues


def _check_poc_equivalence(
    poc_dir: Path,
    attack_doc: AttackVectorDocument,
) -> tuple[bool, list[str]]:
    main_path = poc_dir / "main.go"
    attack_path = poc_dir / "attack_vector.json"
    if not main_path.exists():
        return False, ["main.go not found"]
    if not attack_path.exists():
        return False, ["attack_vector.json not found"]

    try:
        main_go = main_path.read_text(encoding="utf-8", errors="ignore")
    except OSError as exc:
        return False, [f"failed to read main.go: {exc}"]
    try:
        attack_json = attack_path.read_text(encoding="utf-8", errors="ignore")
    except OSError as exc:
        return False, [f"failed to read attack_vector.json: {exc}"]

    try:
        return _llm_equivalence_check(main_go, attack_json)
    except Exception as exc:  # noqa: BLE001
        logging.getLogger(__name__).warning("LLM equivalence check failed: %s", exc)
        return False, [f"LLM equivalence check error: {exc}"]


def _llm_equivalence_check(
    main_go: str,
    attack_json: str,
) -> tuple[bool, list[str]]:
    claude_cmd = shutil.which("claude")
    if claude_cmd is None:
        return False, ["claude CLI not found in PATH."]

    prompt = f"""You are a security PoC reviewer. Verify whether main.go correctly implements
the attack procedure in attack_vector.json (equivalence check).

Verify:
1. Message sequence: same messages in same order as attack_sequence?
2. Trigger message: correctly constructs the step with triggers_vulnerability=true?
3. Malicious payload: injects correct malicious value into correct IE field?
4. Prerequisite messages: handles non-trigger messages before trigger?

=== attack_vector.json ===
{attack_json[:8000]}

=== main.go ===
{main_go[:12000]}

Respond EXACTLY:
VERDICT: EQUIVALENT or VERDICT: NOT_EQUIVALENT
REASON: <one sentence>
ISSUES: <comma-separated list, or "none">
"""

    env = dict(subprocess.os.environ)
    env.pop("CLAUDECODE", None)

    proc = subprocess.run(
        [claude_cmd, "-p", "--model", "sonnet", "--no-session-persistence"],
        input=prompt,
        capture_output=True,
        text=True,
        timeout=300,
        env=env,
        check=False,
    )

    if proc.returncode != 0:
        return False, [f"claude CLI exited with code {proc.returncode}: {proc.stderr[:200]}"]

    return _parse_equivalence_response(proc.stdout)


def _parse_equivalence_response(response: str) -> tuple[bool, list[str]]:
    issues: list[str] = []
    lines = response.strip().splitlines()

    verdict_line = ""
    reason_line = ""
    issues_line = ""
    for line in lines:
        stripped = line.strip()
        if stripped.upper().startswith("VERDICT:"):
            verdict_line = stripped
        elif stripped.upper().startswith("REASON:"):
            reason_line = stripped
        elif stripped.upper().startswith("ISSUES:"):
            issues_line = stripped

    is_equivalent = "EQUIVALENT" in verdict_line.upper() and "NOT_EQUIVALENT" not in verdict_line.upper()

    if reason_line:
        reason = reason_line.split(":", 1)[-1].strip()
    else:
        reason = "LLM did not provide a reason."

    if issues_line:
        raw_issues = issues_line.split(":", 1)[-1].strip()
        if raw_issues.lower() != "none" and raw_issues:
            issues = [i.strip() for i in raw_issues.split(",") if i.strip()]

    if not is_equivalent:
        issues.insert(0, f"Equivalence check failed: {reason}")

    return is_equivalent, issues


def _run_go_build(poc_dir: Path) -> tuple[bool, str, str]:
    go_cmd = shutil.which("go")
    if go_cmd is None:
        return False, "", "go command not found in PATH"

    proc = subprocess.run(
        [go_cmd, "build", "-o", "poc_binary", "."],
        cwd=str(poc_dir),
        capture_output=True,
        text=True,
        check=False,
    )
    return proc.returncode == 0, proc.stdout, proc.stderr


def _infer_crash_type(lowered_logs: str) -> str:
    if "heap-buffer-overflow" in lowered_logs or "asan" in lowered_logs:
        return "heap_buffer_overflow"
    if "assert" in lowered_logs:
        return "assertion_failure"
    if "panic" in lowered_logs:
        return "panic"
    if "segmentation fault" in lowered_logs or "segfault" in lowered_logs:
        return "segfault"
    if "fatal" in lowered_logs:
        return "fatal"
    return "unknown_crash"


def _extract_crash_location(logs: str) -> dict[str, Any]:
    file_line = re.search(
        r"(?P<file>[A-Za-z0-9_./-]+\.(?:c|cc|cpp|cxx|go|h)):(?P<line>\d+)",
        logs,
    )
    function = re.search(r"\bin\s+([A-Za-z_][A-Za-z0-9_]*)\b", logs)

    return {
        "file": file_line.group("file") if file_line else "unknown",
        "line": int(file_line.group("line")) if file_line else 0,
        "function": function.group(1) if function else "unknown",
    }


def _extract_log_snippet(logs: str, max_lines: int = 12) -> list[str]:
    lines = [line for line in logs.splitlines() if line.strip()]
    selected: list[str] = []
    for line in lines:
        low = line.lower()
        if any(k in low for k in _CRASH_KEYWORDS) or any(p in low for p, _, _ in _DIAGNOSIS_RULES):
            selected.append(line)
        if len(selected) >= max_lines:
            break
    if selected:
        return selected
    return lines[-max_lines:]


def _extract_missing_ie(logs: str) -> str | None:
    m = re.search(r"missing mandatory ie[:\s]+([A-Za-z0-9_]+)", logs, flags=re.IGNORECASE)
    if m:
        return m.group(1)
    return None


def _is_expected_crash(
    *,
    location: dict[str, Any],
    expected_file: str | None,
    expected_function: str | None,
) -> bool:
    if expected_file is None and expected_function is None:
        return True
    if expected_file and expected_file not in str(location.get("file", "")):
        return False
    if expected_function and expected_function != str(location.get("function", "")):
        return False
    return True


def _prepend_messages_if_missing(data: dict[str, Any], messages: list[str]) -> None:
    seq = data["attack_vector"]["attack_sequence"]
    existing = {step.get("message") for step in seq}
    to_add = [msg for msg in messages if msg not in existing]
    if not to_add:
        return

    new_steps: list[dict[str, Any]] = []
    for i, msg in enumerate(to_add, start=1):
        new_steps.append(
            {
                "step": i,
                "message": msg,
                "manipulation": {
                    "ie": "NodeID",
                    "field": "value",
                    "malicious_value": "<benign_placeholder>",
                },
                "triggers_vulnerability": False,
            }
        )
        data["protocol_messages"].setdefault(
            msg,
            _build_protocol_message_spec(
                message_name=msg,
                mandatory_ies=[],
                trigger_ie="NodeID",
                ie_field="value",
                malicious_value="<benign_placeholder>",
                include_attack_payload=False,
            ),
        )

    merged = new_steps + seq
    for idx, step in enumerate(merged, start=1):
        step["step"] = idx
    data["attack_vector"]["attack_sequence"] = merged
